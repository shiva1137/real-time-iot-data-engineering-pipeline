 COPY-PASTE READY PROMPTS FOR CURSOR AI
IoT Data Engineering Project - All 12 Topics

================================================================================
üìã CRITICAL CODING STYLE GUIDELINES - READ THIS FIRST
================================================================================

**FUNCTION-FIRST APPROACH:**
- Use **functions as the primary approach** for all code
- Use **classes only when absolutely required** by frameworks (FastAPI Pydantic models, etc.)
- Keep code simple, readable, and function-based
- Prefer pure functions with parameters and return values
- Use module-level variables for simple state management
- Avoid classes for business logic, data processing, or utilities

**When Classes Are Acceptable:**
1. FastAPI Pydantic models (BaseModel) - REQUIRED by framework
2. Library requirements (if library expects classes)
3. Complex state management (but prefer function parameters first)

**When to Use Functions:**
- All data processing logic
- All business logic
- All utility functions
- All validation logic
- All transformation logic
- All calculation functions

**For every topic, prioritize functions over classes. Only use classes when the framework/library explicitly requires it.**

**Implementation Checklist:**
- [ ] All business logic is in functions
- [ ] No classes for data processing
- [ ] No classes for utilities
- [ ] Classes only for framework requirements (Pydantic, etc.)
- [ ] Functions are pure when possible (no side effects)
- [ ] State passed as parameters, not class attributes
- [ ] Module-level constants and state are clearly marked
- [ ] Functions have clear docstrings
- [ ] Functions are testable (easy to unit test)

================================================================================
üìö LEARNING METHODOLOGY: REAL-WORLD DATA ENGINEERING APPROACH
================================================================================

**CRITICAL INSTRUCTION FOR ALL TOPICS:**

When implementing any topic, you MUST provide:

### 1. REAL-WORLD PROBLEMS & CHALLENGES

For each topic, include **actual problems data engineers face daily** in production.

**Format for Each Problem:**
```
Problem: [Real-world scenario]
Why It Happens: [Root cause explanation]
Impact: [What happens if not handled]
Solution: [How to handle it]
Prevention: [How to prevent it]
Code Example: [Implementation]
```

**Examples by Topic:**
- **Topic 2 (Kafka)**: Network partitions, broker failures, consumer lag, duplicate messages, schema evolution
- **Topic 3 (Spark Streaming)**: Late data handling, state management issues, checkpoint failures, memory pressure
- **Topic 4 (Batch Processing)**: Job failures, data skew, slow queries, out-of-memory errors, partition issues
- **Topic 5 (Data Quality)**: Schema drift, data quality degradation, false positives in validation, DLQ overflow
- **Topic 6 (dbt)**: Model failures, dependency issues, incremental model breaks, test failures
- **Topic 7 (FastAPI)**: API timeouts, database connection issues, caching problems, rate limiting
- **Topic 8 (Airflow)**: DAG failures, task retries, dependency issues, backfill problems
- **Topic 9 (Monitoring)**: Alert fatigue, log volume issues, metric accuracy, performance impact
- **Topic 10 (Docker)**: Container crashes, volume issues, network problems, build failures
- **Topic 11 (CI/CD)**: Pipeline failures, test flakiness, deployment issues, rollback scenarios

### 2. COMPREHENSIVE EXPLANATIONS (WHY, WHAT, HOW TO, WHAT IF)

For EVERY implementation decision, provide:

#### A. WHY (Design Decisions)
**Format:**
```
WHY [Decision]?
Business Reason: [Why it matters for business]
Technical Reason: [Why it's technically better]
Trade-offs: [What we gain vs what we lose]
Alternatives Considered: [What else we could have done]
Why Not Alternatives: [Why we didn't choose them]
```

**Key Questions to Answer:**
- Why this technology? (Kafka vs RabbitMQ, Spark vs Flink, etc.)
- Why this approach? (Streaming vs Batch, MongoDB vs PostgreSQL, etc.)
- Why this configuration? (Partitions, retention, window size, etc.)
- Why this pattern? (DLQ, idempotency, checkpointing, etc.)

#### B. WHAT (Concepts & Definitions)
**Format:**
```
WHAT is [Concept]?
Definition: [Clear, concise definition]
Purpose: [What problem it solves]
How It Works: [Step-by-step explanation]
Key Components: [Main parts]
Types/Variants: [Different approaches]
Real-World Analogy: [Easy-to-understand comparison]
```

**Key Concepts to Explain:**
- What is idempotency? Watermarking? Exactly-once? Checkpointing?
- What does it do? (How it works at high level)
- What are the components? (Break down into parts)
- What are the types/variants? (Different approaches)

#### C. HOW TO (Implementation & Usage)
**Format:**
```
HOW TO [Action]?
Step 1: [First step with code example]
Step 2: [Second step with code example]
Step 3: [Third step with code example]
Best Practices: [What to do]
Common Mistakes: [What to avoid]
Code Example: [Complete working example]
```

**Key Actions to Cover:**
- How to implement? (Step-by-step code)
- How to use it? (Usage examples)
- How to configure? (Configuration options)
- How to test? (Testing strategies)
- How to debug? (Debugging techniques)

#### D. WHAT IF (Scenario-Based Questions)
**Format:**
```
WHAT IF [Scenario]?
Problem: [What goes wrong]
Detection: [How to detect it]
Impact: [What's affected]
Solution: [How to fix it]
Prevention: [How to prevent it]
Monitoring: [How to monitor it]
Interview Answer: [How to explain in interview]
```

**Key Scenarios to Cover:**
- What if [component] fails? (Failure scenarios)
- What if [scale]? (10x, 100x, 1000x data volume)
- What if [edge case]? (Edge cases and exceptions)
- What if [change]? (Schema changes, requirement changes)

### 3. INTERVIEW PREPARATION (Comprehensive Q&A)

For each topic, provide:

#### A. Basic Interview Questions
**Format:**
```
Q: [Common interview question]
A: [2-3 sentence concise answer]
Key Points: [3-5 bullet points]
Follow-up Questions: [What they might ask next]
Deep Dive: [Detailed explanation if asked]
Code Example: [If applicable]
Real-World Example: [Production scenario]
```

#### B. System Design Questions
**Format:**
```
Q: "Design a [system] for [requirement]"
A: [Step-by-step design approach]
Components: [What components needed]
Trade-offs: [Design decisions and alternatives]
Scalability: [How to scale]
Reliability: [How to ensure reliability]
```

#### C. Troubleshooting Questions
**Format:**
```
Q: "How would you debug [problem]?"
A: [Systematic debugging approach]
Tools: [What tools to use]
Steps: [Step-by-step process]
Common Causes: [What usually causes this]
Prevention: [How to prevent]
```

#### D. Scenario-Based Questions
**Format:**
```
Q: "What if [real-world scenario]?"
A: [Problem identification + solution]
Prevention: [How to prevent]
Monitoring: [How to detect early]
Trade-offs: [What we gain/lose]
```

### 4. LEARNING-BY-DOING SCENARIOS

For each topic, include:

#### A. Hands-On Exercises
**Format:**
```
Exercise 1: [Name]
Objective: [What to achieve]
Steps: [How to do it]
Expected Result: [What should happen]
Common Issues: [What might go wrong]
Solution: [How to fix issues]
Verification: [How to verify it works]
```

#### B. Common Mistakes to Learn From
**Format:**
```
Common Mistake: [Name]
What Happens: [The mistake]
Why: [Root cause]
Impact: [Consequences]
Fix: [How to correct]
Prevention: [How to avoid]
```

#### C. Production-Like Scenarios
**Format:**
```
Scenario: [Real production situation]
Challenge: [What makes it difficult]
Solution: [How to handle it]
Learning: [What you learn from it]
Code Example: [Implementation]
```

### 5. MODERN DATA ENGINEERING PRACTICES

Include current industry practices:

**Format:**
```
MODERN PRACTICES
Industry Standard: [What's commonly used]
Cloud Deployment: [How to deploy in cloud (AWS, GCP, Azure)]
Observability: [Modern monitoring tools (Grafana, Datadog, etc.)]
Cost Optimization: [How to reduce costs]
Performance: [Optimization techniques]
Security: [Security best practices]
Compliance: [GDPR, HIPAA considerations]
Data Governance: [Data lineage, cataloging]
```

================================================================================
üî• DAILY DATA ENGINEER PROBLEMS - REAL-WORLD SCENARIOS
================================================================================

### Category 1: Data Quality Issues

**Problem 1: Schema Drift in Production**
- **Why**: Source systems evolve, new fields added, old fields deprecated
- **Impact**: Validation failures, pipeline breaks, data loss
- **Solution**: Schema registry, versioning, backward compatibility
- **Prevention**: Schema contracts, automated schema validation

**Problem 2: Data Quality Degradation Over Time**
- **Why**: Sensor calibration drift, system updates, network issues
- **Impact**: Analytics become inaccurate, false alerts
- **Solution**: Continuous monitoring, quality metrics tracking, automated alerts
- **Prevention**: Regular sensor maintenance, quality thresholds

**Problem 3: False Positives in Validation**
- **Why**: Overly strict validation rules, edge cases not considered
- **Impact**: Good data rejected, DLQ overflow, investigation overhead
- **Solution**: Tune thresholds, review validation logic, A/B testing
- **Prevention**: Test validation with real data, gradual rollout

**Problem 4: Missing Data Patterns**
- **Why**: Network failures, sensor outages, upstream issues
- **Impact**: Incomplete analytics, missing insights
- **Solution**: Forward-fill, backward-fill, interpolation, alert on patterns
- **Prevention**: Redundant sensors, network monitoring

**Problem 5: Duplicate Data Explosion**
- **Why**: Network retries, producer failures, consumer rebalancing
- **Impact**: Inflated metrics, storage waste, incorrect aggregations
- **Solution**: Idempotent producers, duplicate detection, deduplication
- **Prevention**: Proper retry logic, message IDs, idempotency

### Category 2: Infrastructure Problems

**Problem 1: Kafka Consumer Lag Spikes**
- **Why**: Slow processing, resource constraints, downstream bottlenecks
- **Impact**: Delayed data, stale analytics, alert storms
- **Solution**: Scale consumers, optimize processing, increase resources
- **Prevention**: Monitor lag, set up alerts, capacity planning

**Problem 2: Spark Job Failures**
- **Why**: Out of memory, data skew, network issues, code bugs
- **Impact**: Pipeline breaks, data not processed, manual intervention
- **Solution**: Increase memory, fix data skew, retry logic, code fixes
- **Prevention**: Resource planning, testing, monitoring

**Problem 3: Database Connection Pool Exhaustion**
- **Why**: Too many connections, connection leaks, slow queries
- **Impact**: Service unavailability, timeouts, user impact
- **Solution**: Increase pool size, fix leaks, optimize queries, connection pooling
- **Prevention**: Monitor connections, set limits, connection timeouts

**Problem 4: Network Partitions**
- **Why**: Network issues, infrastructure problems, misconfiguration
- **Impact**: Service unavailability, data inconsistency, split-brain
- **Solution**: Retry logic, circuit breakers, eventual consistency
- **Prevention**: Network monitoring, redundancy, health checks

**Problem 5: Disk Space Issues**
- **Why**: Log retention, data growth, failed cleanup jobs
- **Impact**: Service failures, data loss, system crashes
- **Solution**: Cleanup jobs, data archival, increase storage
- **Prevention**: Monitoring, retention policies, automated cleanup

### Category 3: Performance Issues

**Problem 1: Slow Query Performance**
- **Why**: Missing indexes, large datasets, inefficient queries, resource constraints
- **Impact**: Poor user experience, timeouts, resource waste
- **Solution**: Add indexes, optimize queries, partition data, increase resources
- **Prevention**: Query analysis, indexing strategy, performance testing

**Problem 2: Memory Pressure**
- **Why**: Large datasets, inefficient algorithms, memory leaks
- **Impact**: OOM errors, job failures, system instability
- **Solution**: Increase memory, optimize algorithms, fix leaks, streaming processing
- **Prevention**: Memory profiling, resource planning, monitoring

**Problem 3: CPU Bottlenecks**
- **Why**: Complex computations, inefficient code, resource contention
- **Impact**: Slow processing, timeouts, poor throughput
- **Solution**: Optimize code, parallelize, increase CPU, use caching
- **Prevention**: Profiling, performance testing, resource planning

**Problem 4: I/O Saturation**
- **Why**: High read/write volume, inefficient I/O, network issues
- **Impact**: Slow operations, timeouts, system instability
- **Solution**: Optimize I/O, use caching, increase I/O capacity
- **Prevention**: I/O monitoring, optimization, capacity planning

### Category 4: Operational Issues

**Problem 1: Pipeline Failures at 2 AM**
- **Why**: Scheduled jobs, resource constraints, data issues
- **Impact**: Delayed data, manual intervention, on-call alerts
- **Solution**: Retry logic, alerting, on-call rotation, automated recovery
- **Prevention**: Robust error handling, monitoring, testing

**Problem 2: Backfill Requirements**
- **Why**: Pipeline failures, data corrections, new requirements
- **Impact**: Manual work, time-consuming, error-prone
- **Solution**: Automated backfill scripts, idempotent jobs, monitoring
- **Prevention**: Reliable pipelines, data quality, testing

**Problem 3: Schema Evolution**
- **Why**: Business requirements change, new features, system updates
- **Impact**: Breaking changes, data loss, compatibility issues
- **Solution**: Versioning, backward compatibility, gradual rollout
- **Prevention**: Schema registry, versioning strategy, testing

**Problem 4: Dependency Conflicts**
- **Why**: Multiple services, version mismatches, library conflicts
- **Impact**: Build failures, runtime errors, compatibility issues
- **Solution**: Dependency management, version pinning, testing
- **Prevention**: Dependency tracking, version control, CI/CD

### Category 5: Monitoring & Alerting

**Problem 1: Alert Fatigue**
- **Why**: Too many alerts, false positives, unclear priorities
- **Impact**: Important alerts ignored, delayed response, burnout
- **Solution**: Alert prioritization, aggregation, tuning thresholds
- **Prevention**: Smart alerting, alert grouping, clear priorities

**Problem 2: Missing Critical Alerts**
- **Why**: Alert misconfiguration, monitoring gaps, alert failures
- **Impact**: Undetected issues, data loss, service outages
- **Solution**: Alert testing, redundancy, monitoring coverage
- **Prevention**: Comprehensive monitoring, alert testing, reviews

**Problem 3: Log Volume Explosion**
- **Why**: Verbose logging, high traffic, log retention issues
- **Impact**: Storage costs, slow queries, performance impact
- **Solution**: Log levels, log aggregation, retention policies
- **Prevention**: Structured logging, log sampling, monitoring

================================================================================
üéØ TOPIC 1: Project Setup & Architecture
I'm starting Topic 1: Project Setup & Architecture from my IoT Data Engineering Project.Reference: Learning Guide.txt in my workspace (all 5827 lines)Please help me:1. **Create Complete Folder Structure:**   Create the entire project structure following best practices:   
iot-data-pipeline/
‚îú‚îÄ‚îÄ data_generator/ # Topic 2: Faker data generator
‚îÇ ‚îú‚îÄ‚îÄ init.py
‚îÇ ‚îú‚îÄ‚îÄ generator.py
‚îÇ ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ kafka/ # Topic 2: Kafka configs
‚îÇ ‚îú‚îÄ‚îÄ topics_config.json
‚îÇ ‚îú‚îÄ‚îÄ init_topics.py  # Python script (production-ready)
‚îÇ ‚îî‚îÄ‚îÄ init-topics.sh  # DEPRECATED: Use init_topics.py
‚îú‚îÄ‚îÄ spark_streaming/ # Topic 3: Real-time processing
‚îÇ ‚îú‚îÄ‚îÄ init.py
‚îÇ ‚îú‚îÄ‚îÄ streaming_job.py
‚îÇ ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ spark_batch/ # Topic 4: Daily batch jobs
‚îÇ ‚îú‚îÄ‚îÄ init.py
‚îÇ ‚îú‚îÄ‚îÄ batch_job.py
‚îÇ ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ data_quality/ # Topic 5: Validation logic
‚îÇ ‚îú‚îÄ‚îÄ init.py
‚îÇ ‚îú‚îÄ‚îÄ validators.py
‚îÇ ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ dbt/ # Topic 6: dbt project
‚îÇ ‚îú‚îÄ‚îÄ models/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ staging/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ intermediate/
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ marts/
‚îÇ ‚îú‚îÄ‚îÄ tests/
‚îÇ ‚îú‚îÄ‚îÄ dbt_project.yml
‚îÇ ‚îî‚îÄ‚îÄ profiles.yml
‚îú‚îÄ‚îÄ api/ # Topic 7: FastAPI
‚îÇ ‚îú‚îÄ‚îÄ init.py
‚îÇ ‚îú‚îÄ‚îÄ main.py
‚îÇ ‚îú‚îÄ‚îÄ models/
‚îÇ ‚îú‚îÄ‚îÄ routes/
‚îÇ ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ airflow/ # Topic 8: DAGs
‚îÇ ‚îú‚îÄ‚îÄ dags/
‚îÇ ‚îú‚îÄ‚îÄ logs/
‚îÇ ‚îî‚îÄ‚îÄ plugins/
‚îú‚îÄ‚îÄ monitoring/ # Topic 9: Logs, alerts
‚îÇ ‚îú‚îÄ‚îÄ logging_config.py
‚îÇ ‚îî‚îÄ‚îÄ alerts.py
‚îú‚îÄ‚îÄ docker/ # Topic 10: Dockerfiles
‚îÇ ‚îú‚îÄ‚îÄ Dockerfile.generator
‚îÇ ‚îú‚îÄ‚îÄ Dockerfile.spark
‚îÇ ‚îú‚îÄ‚îÄ Dockerfile.api
‚îÇ ‚îî‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .github/ # Topic 11: CI/CD
‚îÇ ‚îî‚îÄ‚îÄ workflows/
‚îÇ ‚îî‚îÄ‚îÄ ci.yml
‚îú‚îÄ‚îÄ docs/ # Documentation
‚îÇ ‚îî‚îÄ‚îÄ architecture.md
‚îú‚îÄ‚îÄ scripts/ # Utility scripts
‚îÇ ‚îú‚îÄ‚îÄ setup.py  # Python script (production-ready)
‚îÇ ‚îî‚îÄ‚îÄ setup.sh  # DEPRECATED: Use setup.py
‚îú‚îÄ‚îÄ tests/ # Test files
‚îÇ ‚îî‚îÄ‚îÄ init.py
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
2. **Initialize Git Repository:**   - Create .gitignore for Python, Docker, IDE files, environment variables   - Initialize git repository   - Create initial commit message3. **Create docker-compose.yml:**   - MongoDB service (port 27017)   - PostgreSQL service (port 5432)   - Kafka service (KRaft mode, port 9092) - NO Zookeeper   - Network configuration (iot_network)   - Volume mounts for persistence   - Environment variables setup4. **Create README.md:**   - Project overview (100 sensors, 864K readings/day)   - Architecture diagram (ASCII text-based)   - Setup instructions   - How to run: docker-compose up   - Project structure explanation5. **Create .env.example:**   - Template for MongoDB, PostgreSQL, Kafka connection strings   - All environment variables with comments6. **Create requirements.txt:**   - Placeholder with comments for future dependencies**INTERVIEW PREPARATION - Please also provide:**1. **Architecture Explanation:**   - Why this folder structure? (Separation of concerns, scalability)   - How does data flow through the system?   - Why Docker Compose? (Local development, reproducibility)2. **Design Decisions - Answer These:**   - "Why did you choose Kafka over RabbitMQ/RabbitMQ/Redis?"     ‚Üí Provide answer: High throughput, durability, partitioning   - "Why MongoDB + PostgreSQL instead of just one?"     ‚Üí Provide answer: MongoDB for writes (high volume), PostgreSQL for reads (SQL queries)   - "Why KRaft instead of Zookeeper?"     ‚Üí Provide answer: Modern approach, simpler, no external dependency   - "How do you handle data flow?"     ‚Üí Provide answer: Kafka ‚Üí Spark Streaming/Batch ‚Üí MongoDB (write) ‚Üí PostgreSQL (read) ‚Üí API3. **What-If Scenarios - Prepare Answers:**   - "What if Kafka goes down?" ‚Üí Answer: Producer retries, data buffered, DLQ for failures   - "What if MongoDB fails?" ‚Üí Answer: Write failures logged, retry mechanism, alert triggered   - "What if PostgreSQL fails?" ‚Üí Answer: Read operations fail, but writes continue to MongoDB   - "How would you scale this?" ‚Üí Answer: Horizontal scaling, more partitions, distributed Spark4. **Code Quality:**   - Follow Python best practices   - Add comments explaining architecture decisions   - Include docstringsPlease create all files and explain the structure. I want to understand why each folder/file is needed.
üéØ TOPIC 2: Data Ingestion with Kafka

I'm working on Topic 2: Data Ingestion with Kafka.
Reference: Learning Guide.txt - Topic 2 section and Layer 1 architecture

Please help me implement:

1. **Kafka Broker Setup (KRaft Mode):**
   - Update docker-compose.yml with Kafka in KRaft mode (no Zookeeper)
   - Configure KRaft-specific environment variables
   - Create init script to auto-create topics:
     * raw_iot_data (3 partitions)
     * validated_iot_data (3 partitions)
     * dlq_iot_data (1 partition for dead-letter queue)

2. **Faker Data Generator:**
   - Build Python script that simulates 100 IoT sensors
   - Generate realistic data:
     * sensor_id, location, device_type
     * temperature (-5 to 45¬∞C with realistic variation)
     * humidity (20-80%)
     * energy_consumption (0.5-5 kWh)
     * timestamp, signal_strength, battery_level
   - Send data every 10 seconds per sensor
   - Add random failures (5% chance) to simulate real-world issues

3. **Kafka Producer Implementation:**
   - Use kafka-python library
   - Implement idempotent producer (enable.idempotence=true)
   - Partitioning strategy: hash(sensor_id) % 3
   - Error handling:
     * Retry with exponential backoff (5s ‚Üí 10s ‚Üí 20s)
     * Log failures
     * Queue locally if Kafka unavailable
   - Add unique message_id for deduplication

4. **Validation Consumer:**
   - Read from raw_iot_data topic
   - Validate:
     * Schema (all required fields present)
     * Types (temperature is float, timestamp is valid)
     * Ranges (temperature -50 to 50¬∞C, humidity 0-100%)
     * Freshness (timestamp < 5 minutes old)
     * Duplicates (same sensor_id + timestamp)
   - Send valid data to validated_iot_data
   - Send invalid data to dlq_iot_data
   - Log quality metrics (% valid, % invalid)

================================================================================
üìä REAL-WORLD DATA ENGINEERING CHALLENGES
================================================================================

**Challenge 1: Kafka Consumer Lag Spikes**
- **Problem**: Consumer falls behind, lag increases to hours/days
- **Why It Happens**: Slow processing, resource constraints, downstream bottlenecks, network issues
- **Impact**: Stale data, delayed analytics, alert storms, potential data loss
- **Solution**: 
  * Scale consumers horizontally (add more consumer instances)
  * Optimize processing logic (reduce computation time)
  * Increase consumer resources (CPU, memory)
  * Tune batch size and fetch size
  * Monitor lag metrics and set up alerts
- **Prevention**: 
  * Capacity planning before deployment
  * Monitor lag continuously
  * Set up alerts at 5-minute lag threshold
  * Load testing before production
- **Code Example**: Monitor lag with kafka-python consumer.metrics()

**Challenge 2: Network Partitions and Broker Failures**
- **Problem**: Kafka broker becomes unavailable, network connectivity issues
- **Why It Happens**: Infrastructure failures, network issues, broker crashes, misconfiguration
- **Impact**: Producer/consumer failures, data not ingested, service unavailability
- **Solution**:
  * Producer retry logic with exponential backoff
  * Local message queue for resilience
  * Health checks and automatic reconnection
  * Circuit breaker pattern
  * Multi-broker setup for redundancy
- **Prevention**:
  * Multi-broker cluster (replication factor > 1)
  * Network monitoring
  * Health checks
  * Proper error handling in producer/consumer
- **Code Example**: Retry logic with exponential backoff in producer

**Challenge 3: Duplicate Messages**
- **Problem**: Same message appears multiple times in topic
- **Why It Happens**: Network retries, producer failures, consumer rebalancing, idempotency not enabled
- **Impact**: Inflated metrics, incorrect aggregations, storage waste
- **Solution**:
  * Enable idempotent producer (enable.idempotence=true)
  * Use unique message_id for deduplication
  * Consumer-side duplicate detection
  * Idempotent writes in downstream systems
- **Prevention**:
  * Always enable idempotency for critical data
  * Use message IDs consistently
  * Test retry scenarios
- **Code Example**: Idempotent producer configuration

**Challenge 4: Schema Evolution**
- **Problem**: Source system adds new fields, breaking downstream consumers
- **Why It Happens**: Business requirements change, system updates, new features
- **Impact**: Consumer failures, data loss, breaking changes
- **Solution**:
  * Schema registry (Confluent Schema Registry)
  * Backward/forward compatibility
  * Versioned schemas
  * Gradual rollout
- **Prevention**:
  * Schema versioning strategy
  * Compatibility checks
  * Testing with schema changes
- **Code Example**: Schema validation in consumer

**Challenge 5: DLQ Overflow**
- **Problem**: Dead-letter queue fills up with invalid messages
- **Why It Happens**: High validation failure rate, sensor issues, validation bugs
- **Impact**: Storage issues, investigation overhead, potential data loss
- **Solution**:
  * Alert on DLQ size threshold
  * Investigate root cause
  * Fix validation logic or sensors
  * Increase retention if needed
  * Manual reprocessing after fixes
- **Prevention**:
  * Monitor DLQ size continuously
  * Alert at 1GB threshold
  * Regular investigation of failures
  * Tune validation thresholds
- **Code Example**: DLQ monitoring and alerting

================================================================================
‚ùì WHY, WHAT, HOW TO, WHAT IF - COMPREHENSIVE EXPLANATIONS
================================================================================

**WHY Idempotent Producer?**

**Business Reason**: 
- Prevents duplicate data in analytics (critical for accurate metrics)
- Reduces investigation time for duplicate issues
- Ensures data accuracy for business decisions

**Technical Reason**:
- Enables exactly-once semantics
- Safe retries without creating duplicates
- Uses producer ID + sequence number for deduplication
- Critical for financial/analytical accuracy

**Trade-offs**:
- Gain: Data accuracy, exactly-once semantics
- Lose: Slight performance overhead, requires acks='all'

**Alternatives Considered**:
- At-least-once: Simpler but requires downstream deduplication
- At-most-once: Fastest but potential data loss

**Why Not Alternatives**:
- At-least-once: Downstream deduplication is complex and error-prone
- At-most-once: Data loss is unacceptable for analytics

---

**WHAT is Idempotency?**

**Definition**: 
An operation that can be applied multiple times without changing the result beyond the initial application.

**Purpose**: 
Prevents duplicate messages when producer retries after failures.

**How It Works**:
1. Kafka assigns unique producer ID to each producer
2. Each message gets sequence number per partition
3. Broker tracks (producer_id, partition, sequence_number)
4. If duplicate sequence number received, broker rejects it
5. Producer can safely retry without creating duplicates

**Key Components**:
- Producer ID (unique per producer instance)
- Sequence Number (per partition, per producer)
- Broker-side deduplication logic

**Types/Variants**:
- Producer-level idempotency (Kafka native)
- Application-level idempotency (message IDs)
- Consumer-level deduplication (tracking seen messages)

**Real-World Analogy**: 
Like a bank transaction - if you retry a payment, the bank ensures it's only processed once, not twice.

---

**HOW TO Implement Idempotent Producer?**

**Step 1**: Enable idempotence in producer config
```python
producer = KafkaProducer(
    bootstrap_servers='localhost:9092',
    enable_idempotence=True,  # Enable idempotency
    acks='all'  # Required for idempotency
)
```

**Step 2**: Add unique message_id to each record
```python
record = {
    "message_id": str(uuid.uuid4()),
    "sensor_id": "SENSOR_001",
    "temperature": 25.5
}
```

**Step 3**: Implement retry logic with exponential backoff
```python
def send_with_retry(producer, record, max_retries=3):
    for attempt in range(max_retries):
        try:
            future = producer.send(topic, value=record)
            future.get(timeout=10)
            return True
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(5 * (2 ** attempt))  # Exponential backoff
            else:
                return False
```

**Best Practices**:
- Always enable idempotence for critical data
- Use acks='all' for durability
- Add message_id for application-level deduplication
- Monitor producer metrics

**Common Mistakes**:
- Forgetting acks='all' (idempotency requires it)
- Not handling retry exceptions
- Not monitoring for duplicates
- Using same producer ID across restarts incorrectly

---

**WHAT IF Kafka Broker Crashes?**

**Problem**: 
Kafka broker becomes unavailable, producer cannot send messages.

**Detection**:
- Producer throws KafkaError or KafkaTimeoutError
- Health checks fail
- Monitoring alerts fire
- Consumer lag increases

**Impact**:
- Data not ingested
- Analytics become stale
- Potential data loss if not handled

**Solution**:
1. Producer retries with exponential backoff (5s ‚Üí 10s ‚Üí 20s)
2. Queue messages locally if Kafka unavailable
3. Resume sending when Kafka recovers
4. Alert operations team
5. Investigate root cause

**Prevention**:
- Multi-broker cluster (replication)
- Health checks and monitoring
- Proper error handling
- Local queue for resilience

**Monitoring**:
- Producer error rate
- Queue size
- Kafka broker health
- Consumer lag

**Interview Answer**:
"We handle Kafka broker crashes with multiple layers: First, producer retries with exponential backoff. If Kafka is still unavailable, messages are queued locally. Once Kafka recovers, queued messages are automatically sent. We also have multi-broker setup for redundancy. This ensures no data loss and automatic recovery."

---

**WHAT IF 10x Data Volume?**

**Problem**: 
Data volume increases 10x, current setup cannot handle it.

**Detection**:
- Consumer lag increases
- Processing time increases
- Resource utilization spikes
- Timeouts occur

**Impact**:
- System becomes slow or unavailable
- Data processing delays
- Poor user experience

**Solution**:
1. **Scale Kafka**: Add more partitions (e.g., 3 ‚Üí 30)
2. **Scale Consumers**: Add more consumer instances
3. **Scale Brokers**: Add more Kafka brokers
4. **Optimize**: Optimize processing logic, increase resources
5. **Partition Strategy**: Review partitioning strategy

**Prevention**:
- Capacity planning
- Load testing
- Monitoring and alerting
- Auto-scaling (if in cloud)

**Monitoring**:
- Throughput metrics
- Consumer lag
- Resource utilization
- Processing latency

**Interview Answer**:
"To handle 10x data volume, I'd scale horizontally: Increase Kafka partitions to 30, add more consumer instances, and scale brokers. I'd also optimize processing logic and increase resources. The key is horizontal scaling - Kafka partitions enable parallel processing, so more partitions = more parallelism."

================================================================================
üé§ INTERVIEW PREPARATION - COMPREHENSIVE Q&A
================================================================================

**Basic Questions:**

**Q: "How do you ingest streaming data?"**

**A**: 
"We use Kafka as a message queue for streaming data ingestion. The producer sends sensor data with idempotency enabled to prevent duplicates. We partition by sensor_id using hash partitioning to maintain order per sensor while enabling parallel processing. A validation consumer reads from raw_iot_data, performs comprehensive quality checks (schema, types, ranges, freshness, duplicates), and routes valid data to validated_iot_data or invalid data to dlq_iot_data with detailed failure reasons."

**Key Points**:
- Kafka for high-throughput streaming
- Idempotent producer for exactly-once semantics
- Hash partitioning by sensor_id for ordering
- Multi-layer validation
- DLQ for invalid data

**Follow-up Questions**:
- "Why Kafka over RabbitMQ?"
- "How do you handle duplicates?"
- "What happens if validation is slow?"

**Deep Dive**:
Kafka provides durability, partitioning, and consumer groups. Idempotency ensures no duplicates on retry. Partitioning maintains order per sensor. Validation catches issues early. DLQ enables debugging without data loss.

---

**System Design:**

**Q: "Design a streaming data ingestion system for 1 million sensors"**

**A**:
"Step 1: Kafka cluster with 100+ partitions for parallelism. Step 2: Multiple producer instances with idempotency. Step 3: Consumer groups with 100+ consumer instances. Step 4: Validation layer with parallel processing. Step 5: DLQ for failures. Step 6: Monitoring for lag, throughput, errors."

**Components**:
- Kafka cluster (multiple brokers)
- Producer pool (multiple instances)
- Consumer group (scaled horizontally)
- Validation service (scaled horizontally)
- DLQ topic
- Monitoring system

**Trade-offs**:
- More partitions = more parallelism but more overhead
- More consumers = faster processing but more resources
- Validation at ingestion = early detection but adds latency

**Scalability**:
- Horizontal scaling of all components
- Partition-based parallelism
- Load balancing

---

**Troubleshooting:**

**Q: "How would you debug high consumer lag?"**

**A**:
"Step 1: Check consumer lag metrics. Step 2: Identify which partitions have lag. Step 3: Check consumer processing time. Step 4: Check resource utilization (CPU, memory). Step 5: Review processing logic for bottlenecks. Step 6: Check downstream systems for issues."

**Tools**:
- Kafka consumer lag metrics
- Application metrics (processing time)
- Resource monitoring (CPU, memory)
- Logs analysis

**Steps**:
1. Monitor lag continuously
2. Identify laggy partitions
3. Profile processing logic
4. Check resource constraints
5. Optimize or scale

**Common Causes**:
- Slow processing logic
- Resource constraints
- Downstream bottlenecks
- Network issues

---

**Scenario-Based:**

**Q: "What if 50% of messages fail validation?"**

**A**:
"This indicates a serious data quality issue. I'd: 1) Alert immediately (HIGH severity), 2) Investigate which sensors/fields are failing, 3) Check for sensor health issues or upstream problems, 4) Review validation logic for false positives, 5) Implement temporary workarounds if needed, 6) Fix root cause (sensors, validation, or upstream)."

**Prevention**:
- Monitor validation failure rate
- Alert on threshold breaches
- Regular sensor health checks
- Test validation logic with real data

**Monitoring**:
- Validation failure rate
- Failure types breakdown
- Sensor-level metrics
- DLQ size

================================================================================
üß™ LEARNING-BY-DOING EXERCISES
================================================================================

**Exercise 1: Simulate Kafka Broker Failure**

**Objective**: 
Understand how producer handles broker failures and test retry logic.

**Steps**:
1. Start Kafka and producer
2. Stop Kafka broker (docker stop iot_kafka)
3. Observe producer behavior (retries, local queue)
4. Restart Kafka
5. Verify queued messages are sent

**Expected Result**:
- Producer retries with exponential backoff
- Messages queued locally
- Messages sent when Kafka recovers
- No data loss

**Common Issues**:
- Producer crashes instead of queuing
- Queue fills up
- Messages not sent after recovery

**Solution**:
- Implement proper error handling
- Set queue size limits
- Test recovery scenarios

**Verification**:
- Check producer logs for retry messages
- Verify queue size increases
- Confirm messages sent after recovery

---

**Exercise 2: Test Duplicate Detection**

**Objective**: 
Verify idempotent producer prevents duplicates.

**Steps**:
1. Send message with same message_id twice
2. Check topic for duplicates
3. Verify only one message exists
4. Test with different message_ids

**Expected Result**:
- Same message_id: Only one message in topic
- Different message_ids: Both messages in topic

**Common Issues**:
- Duplicates still appear (idempotency not working)
- Messages rejected incorrectly

**Solution**:
- Verify enable_idempotence=True
- Check acks='all' is set
- Review producer configuration

---

**Common Mistake: Forgetting acks='all' with Idempotency**

**What Happens**: 
Idempotency doesn't work correctly, duplicates may still occur.

**Why**: 
Idempotency requires acks='all' to ensure all replicas acknowledge before considering message committed.

**Impact**: 
Duplicates in topic, incorrect analytics, data quality issues.

**Fix**: 
Always set acks='all' when enable_idempotence=True.

**Prevention**: 
- Code review checklist
- Configuration validation
- Testing with duplicate scenarios

================================================================================
üöÄ MODERN DATA ENGINEERING PRACTICES
================================================================================

**Industry Standards**:
- Kafka 3.0+ with KRaft (Zookeeper deprecated)
- Idempotent producers for exactly-once semantics
- Schema Registry for schema management
- Consumer groups for parallel processing
- DLQ pattern for error handling

**Cloud Deployment (AWS Example)**:
- Use Amazon MSK (Managed Streaming for Kafka)
- Auto-scaling consumer groups
- CloudWatch for monitoring
- S3 for long-term storage
- Lambda for serverless processing

**Observability**:
- Prometheus + Grafana for metrics
- ELK stack for log aggregation
- Distributed tracing (Jaeger)
- Real-time dashboards for lag, throughput

**Cost Optimization**:
- Right-size partitions (not too many, not too few)
- Compress messages (snappy, gzip)
- Set appropriate retention (7 days default)
- Use spot instances for non-critical consumers
- Monitor and optimize resource usage

**Performance**:
- Batch messages (linger.ms)
- Compress messages
- Tune fetch size
- Optimize serialization
- Use async processing where possible

**Security**:
- TLS for encryption in transit
- SASL for authentication
- ACLs for authorization
- Secrets management (AWS Secrets Manager)
- Network isolation (VPC)

**Compliance**:
- Data retention policies
- Audit logging
- Data encryption
- Access controls
- GDPR considerations (data deletion)

================================================================================
üéØ TOPIC 3: Real-Time Processing with Spark Streaming

I'm working on Topic 3: Real-Time Processing with Spark Streaming.
Reference: Learning Guide.txt - Topic 3 and Layer 2 architecture

**NOTE**: Follow the same comprehensive format as Topic 2:
- Real-world challenges (late data, state management, checkpoint failures, memory pressure)
- WHY/WHAT/HOW TO/WHAT IF explanations
- Comprehensive interview Q&A
- Learning-by-doing exercises
- Modern practices (cloud deployment, observability, cost optimization)

Please help me implement:1. **Spark Streaming Setup:**   - Configure Spark to consume from Kafka (validated_iot_data topic)   - Use Structured Streaming API   - Set micro-batch interval: 10 seconds   - Enable checkpointing for fault tolerance2. **5-Minute Tumbling Windows:**   - Group data by 5-minute windows   - Window by timestamp column   - Calculate per sensor per window:     * avg_temperature     * max_temperature     * min_temperature     * avg_humidity     * total_energy_consumption     * count (number of readings)3. **Watermarking & Late Data:**   - Set watermark: 1 minute allowed lateness   - Handle late-arriving data:     * If within watermark: Update window result     * If beyond watermark: Drop (too late)   - Use UPDATE output mode (show latest results)4. **State Management:**   - Implement stateful processing with RocksDB   - Store window state across micro-batches   - Cleanup old windows after watermark expires   - Checkpoint state for recovery5. **Output to MongoDB:**   - Write aggregations to MongoDB (write-only)   - Collection: real_time_aggregates   - Update existing windows (overwrite)   - Index on sensor_id + window_start6. **Data Sync to PostgreSQL:**   - Create sync job that reads from MongoDB   - Syncs to PostgreSQL for querying   - Runs every 5 minutes   - Handles conflicts (last write wins)**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why 5-minute windows? (Balance between real-time and efficiency)   - Why watermarking? (Handle late data without infinite state)   - Why UPDATE mode? (Show latest results in dashboards)   - Why RocksDB? (Fast local state, checkpointable)2. **Interview Questions - Prepare Answers:**      Q: "Design a real-time aggregation pipeline"   ‚Üí Answer: "Spark Streaming consumes from Kafka. Groups by 5-min windows. Calculates aggregations per sensor. Uses watermarking for late data. Writes to MongoDB, synced to PostgreSQL for queries."      Q: "How do you handle late data?"   ‚Üí Answer: "Watermarking with 1-minute lateness. Data within watermark updates window. Beyond watermark is dropped. Prevents infinite state growth while handling network delays."      Q: "Explain windowing operations"   ‚Üí Answer: "Tumbling windows: non-overlapping 5-min buckets. Each window aggregates independently. Sliding windows would overlap. Tumbling is simpler and more efficient for our use case."      Q: "What's exactly-once semantics in Spark?"   ‚Üí Answer: "Each record processed exactly once, even with failures. Achieved via idempotent writes, checkpointing, and transactional output. Prevents duplicate aggregations."      Q: "How do you avoid data loss?"   ‚Üí Answer: "Checkpointing saves state. If Spark crashes, restarts from checkpoint. Kafka offset tracking ensures no message skipped. Idempotent writes prevent duplicates."      Q: "Spark Streaming vs Kafka Streams?"   ‚Üí Answer: "Spark Streaming: More flexible, can do complex ML, larger ecosystem. Kafka Streams: Lighter, lower latency, tighter Kafka integration. We chose Spark for flexibility and ML capabilities."3. **Design Decisions:**   - Why Spark Streaming over Kafka Streams? ‚Üí Flexibility, ML integration, larger ecosystem   - Why 5-min vs 1-min windows? ‚Üí Balance latency vs computation cost   - Why UPDATE vs APPEND mode? ‚Üí Dashboards need latest results, not historical logs   - Why MongoDB for writes? ‚Üí High write throughput, flexible schema4. **What-If Scenarios:**   - "What if Spark crashes mid-window?" ‚Üí Answer: Restart from checkpoint, reprocess from last committed offset   - "What if data arrives 10 minutes late?" ‚Üí Answer: Beyond watermark, dropped. Can adjust watermark if needed.   - "What if window computation is slow?" ‚Üí Answer: Increase parallelism, optimize aggregations, use broadcast joins   - "What if 1000x data volume?" ‚Üí Answer: Scale Spark cluster, increase partitions, use distributed processing   - "What if watermark too strict?" ‚Üí Answer: Increase allowed lateness, but trade-off with state size5. **Code Quality:**   - Comprehensive error handling   - Monitoring metrics (processing time, lag)   - Unit tests for windowing logic   - Performance optimization (broadcast joins, caching)Please provide complete code with detailed comments explaining windowing, watermarking, and state management.
üéØ TOPIC 4: Batch Processing with PySpark

I'm working on Topic 4: Batch Processing with PySpark.
Reference: Learning Guide.txt - Topic 4 and Layer 3 architecture

**NOTE**: Follow the same comprehensive format as Topic 2:
- Real-world challenges (job failures, data skew, slow queries, OOM errors, partition issues)
- WHY/WHAT/HOW TO/WHAT IF explanations
- Comprehensive interview Q&A
- Learning-by-doing exercises
- Modern practices (cloud deployment, observability, cost optimization)

Please help me implement:1. **Daily Batch Job:**   - Trigger: Daily at 2 AM (via Airflow later)   - Read all data from PostgreSQL for previous day (synced from MongoDB)   - Process 864K rows efficiently2. **Data Cleaning:**   - Remove duplicates (same sensor_id + timestamp)   - Handle nulls:     * temperature null ‚Üí drop (critical)     * signal_strength null ‚Üí fill with average     * humidity null ‚Üí drop if > 5% missing   - Remove outliers:     * temperature > 50¬∞C or < -50¬∞C ‚Üí flag as anomaly   - Type conversions and standardization3. **Hourly Aggregation:**   - Group by sensor_id + hour   - Calculate per hour:     * avg_temperature, max_temp, min_temp     * stddev_temperature (for anomaly detection)     * avg_humidity, max_humidity     * total_energy_consumption     * count of readings   - Result: 100 sensors √ó 24 hours = 2,400 rows4. **Feature Engineering:**   - 7-day rolling average (look back 7 days)   - Day-over-day % change   - Anomaly flags:     * If temp > 2 √ó stddev from sensor's mean ‚Üí flag   - Location statistics:     * Compare sensor to city average     * Rank sensors by temperature     * Hottest/coldest location per hour5. **Optimization:**   - Broadcast join for device_metadata (small table)   - Partition output by date + location   - Cache frequently used DataFrames   - Coalesce small files (1-2 files per partition)6. **Write to MongoDB:**   - Write processed data to MongoDB (write-only)   - Collection: processed_daily   - Index on sensor_id, date, location7. **Sync to PostgreSQL:**   - Sync job reads from MongoDB   - Writes to PostgreSQL for dbt transformations   - Handles schema mapping**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why broadcast join? (Small metadata table, avoids shuffle)   - Why partition by date + location? (Optimizes common queries)   - Why cache? (Reuse DataFrames multiple times)   - Why coalesce? (Fewer files = faster reads)2. **Interview Questions - Prepare Answers:**      Q: "How do you optimize Spark jobs?"   ‚Üí Answer: "Broadcast small tables, partition by query patterns, cache hot data, coalesce files, use columnar formats, tune executor memory/cores."      Q: "Explain partitioning strategy"   ‚Üí Answer: "Partition by date + location. Most queries filter by these. Only reads relevant partitions, not entire dataset. Reduces I/O by 90%+."      Q: "Join optimization in Spark"   ‚Üí Answer: "Broadcast join for small tables (< 100MB). Avoids shuffle. For large tables, use bucketing or sort-merge join. Prefer broadcast when possible."      Q: "How do you handle schema changes?"   ‚Üí Answer: "Schema evolution in Spark. Add new columns as nullable. Backfill old data. Use mergeSchema option. Version control schema definitions."      Q: "What's the difference between RDD and DataFrame?"   ‚Üí Answer: "RDD: Low-level, unstructured. DataFrame: High-level, structured, optimized (Catalyst optimizer). We use DataFrame for better performance."      Q: "Caching vs Persisting?"   ‚Üí Answer: "Cache: Default storage level (memory + disk). Persist: Choose storage level (memory_only, disk_only, etc.). Use persist for fine control."3. **Design Decisions:**   - Why batch vs streaming for features? ‚Üí Complex features need full history (7-day rolling avg)   - Why PostgreSQL for reads? ‚Üí SQL queries, dbt compatibility, ACID transactions   - Why MongoDB for writes? ‚Üí High write throughput, flexible schema   - Why daily vs hourly batch? ‚Üí Complete data available, less frequent = more efficient4. **What-If Scenarios:**   - "What if job takes 2 hours instead of 15 mins?" ‚Üí Answer: Optimize joins, increase parallelism, use broadcast, partition better   - "What if out of memory?" ‚Üí Answer: Increase executor memory, use disk persistence, repartition data   - "What if schema changes?" ‚Üí Answer: Schema evolution, backfill, version control   - "What if 10x data volume?" ‚Üí Answer: Scale cluster, increase partitions, optimize aggregations   - "What if join is slow?" ‚Üí Answer: Broadcast small table, bucket large tables, use sort-merge join5. **Code Quality:**   - Modular functions (cleaning, aggregation, features)   - Configuration via YAML/JSON   - Comprehensive logging   - Unit tests for transformationsPlease provide complete code with optimization explanations and performance tips.
üéØ TOPIC 5: Data Quality & Validation

I'm working on Topic 5: Data Quality & Validation.
Reference: Learning Guide.txt - Topic 5 and Layer 4 architecture

**NOTE**: Follow the same comprehensive format as Topic 2:
- Real-world challenges (schema drift, quality degradation, false positives, DLQ overflow)
- WHY/WHAT/HOW TO/WHAT IF explanations
- Comprehensive interview Q&A
- Learning-by-doing exercises
- Modern practices (data governance, compliance, observability)

Please help me implement:1. **Schema Validation:**   - Validate all required fields present   - Check field types (temperature is float, timestamp is datetime)   - Validate field formats (sensor_id matches pattern "sensor_###")2. **Range Validation:**   - Temperature: -50 to 50¬∞C   - Humidity: 0 to 100%   - Energy: 0 to 10 kWh   - Timestamp: Not in future, not > 24 hours old3. **Business Rule Validation:**   - Freshness: timestamp < 5 minutes old   - Anomaly detection: Sudden temp change > 20¬∞C (sensor malfunction)   - Duplicate detection: Same sensor_id + timestamp4. **DLQ (Dead-Letter Queue) Handling:**   - Send failed records to dlq_iot_data Kafka topic   - Include failure reason in message   - Store in MongoDB dlq_failed_records collection   - Retention: 7 days5. **Quality Metrics:**   - Track daily:     * % completeness (required fields present)     * % validity (values in range)     * % timeliness (fresh data)     * % uniqueness (no duplicates)   - Log metrics to file (JSON format)   - Alert if quality drops below threshold (> 10% failures)6. **Alerting:**   - Alert if > 10% messages in DLQ   - Alert if quality metric < 95%   - Alert if data freshness > 5 minutes   - Send alerts to console/log (Slack integration optional)**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why validate at ingestion? (Catch issues early, prevent bad data propagation)   - Why DLQ? (Debugging, don't lose failed messages)   - Why multiple validation points? (Defense in depth)   - Why quality metrics? (Track trends, early warning)2. **Interview Questions - Prepare Answers:**      Q: "How do you validate data?"   ‚Üí Answer: "Multi-layer validation: Schema (fields present, types correct), Range (values in expected range), Business rules (freshness, duplicates). Failed records go to DLQ."      Q: "What quality checks do you implement?"   ‚Üí Answer: "Completeness (all fields), Validity (in range), Timeliness (< 5 min old), Uniqueness (no duplicates), Consistency (matches patterns). Track metrics daily."      Q: "How do you handle bad data?"   ‚Üí Answer: "Send to DLQ with failure reason. Log for investigation. Alert if > 10% failures. Manually fix and replay if needed. Prevent propagation downstream."      Q: "Detecting data drift?"   ‚Üí Answer: "Monitor quality metrics over time. Alert on sudden changes. Track schema changes. Compare distributions. Use statistical tests for anomalies."      Q: "When to alert vs log?"   ‚Üí Answer: "Alert: > 10% failures, quality < 95%, freshness > 5 min. Log: Individual failures, warnings, debug info. Alert = action needed, Log = investigation."3. **Design Decisions:**   - Why validate at ingestion? ‚Üí Catch issues early, prevent downstream problems   - Why DLQ vs dropping? ‚Üí Debugging, understanding failure patterns   - Why multiple thresholds? ‚Üí Different severity levels (warning vs critical)   - Why 7-day retention? ‚Üí Enough time for weekly investigation4. **What-If Scenarios:**   - "What if 50% data fails validation?" ‚Üí Answer: Alert immediately, investigate source, check sensor health, may need recalibration   - "What if validation is slow?" ‚Üí Answer: Parallel validation, async processing, batch validation   - "What if DLQ fills up?" ‚Üí Answer: Increase retention, investigate root cause, fix sensors   - "What if false positives?" ‚Üí Answer: Tune thresholds, review business rules, adjust validation logic   - "What if schema changes?" ‚Üí Answer: Version validation rules, gradual rollout, backward compatibility5. **Code Quality:**   - Modular validators (schema, range, business rules)   - Configurable thresholds   - Comprehensive error messages   - Unit tests for each validatorPlease provide complete code with validation logic, DLQ handling, and quality metrics tracking.
üéØ TOPIC 6: dbt Transformations

I'm working on Topic 6: dbt Transformations.
Reference: Learning Guide.txt - Topic 6 and Layer 5 architecture

**NOTE**: Follow the same comprehensive format as Topic 2:
- Real-world challenges (model failures, dependency issues, incremental breaks, test failures)
- WHY/WHAT/HOW TO/WHAT IF explanations
- Comprehensive interview Q&A
- Learning-by-doing exercises
- Modern practices (dbt Cloud, data lineage, documentation)

Please help me implement:1. **dbt Project Setup:**   - Initialize dbt project   - Configure profiles.yml (PostgreSQL connection)   - Set up dbt_project.yml2. **3-Layer Model Structure:**   **Layer 1: Staging (stg_iot_readings)**   - Read from processed_daily table (PostgreSQL)   - Clean data:     * Rename columns (clarity)     * Convert types (string ‚Üí float, datetime)     * Remove duplicates     * Remove rows with critical nulls   - Add metadata: _loaded_at, _row_number   **Layer 2: Intermediate (int_iot_with_features)**   - Read from stg_iot_readings   - Join with device_metadata (location, device_type)   - Add time features:     * Extract hour, day, week, month     * Is daytime (7 AM - 6 PM)?     * Is weekend?   - Add calculated columns:     * anomaly_flag (temp > 2√óstddev)     * freshness_in_minutes     * sensor_status (Working/Faulty/Recalibration_needed)   **Layer 3: Marts**   - mart_iot_daily_summary:     * Grain: 1 row per sensor per day     * Columns: sensor_id, date, avg_temp, max_temp, min_temp, count   - mart_iot_hourly_summary:     * Grain: 1 row per sensor per hour   - mart_iot_location_stats:     * Grain: 1 row per location per day     * Aggregates across all sensors in location3. **Testing:**   - Unique test: (sensor_id, timestamp) is unique   - Not null tests: sensor_id, temperature, timestamp   - Relationship test: Every sensor_id exists in device_metadata   - Custom test: temperature between -50 and 50   - Freshness test: Data loaded within last 1 hour4. **Documentation:**   - Document each model (purpose, grain)   - Document each column (description, data type)   - Generate data dictionary   - Create lineage diagram5. **Incremental Models:**   - Make daily_summary incremental (only process new dates)   - Use incremental_strategy: merge   - Handle updates vs inserts**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why 3-layer structure? (Separation: clean ‚Üí enrich ‚Üí aggregate)   - Why staging first? (Clean raw data before business logic)   - Why marts? (Pre-aggregated for dashboards, fast queries)   - Why incremental? (Only process new data, faster runs)2. **Interview Questions - Prepare Answers:**      Q: "Explain your dbt structure"   ‚Üí Answer: "3 layers: Staging (clean raw data), Intermediate (add features, joins), Marts (pre-aggregated for analytics). Clear separation, easy to maintain."      Q: "How do you test SQL?"   ‚Üí Answer: "dbt tests: unique, not_null, relationships, custom SQL. Run `dbt test` after transformations. Fail if any test fails. Ensures data quality."      Q: "What's an incremental model?"   ‚Üí Answer: "Only processes new data since last run. Uses merge strategy. Faster than full refresh. Critical for large datasets. Tracks last processed date."      Q: "dbt vs Spark for transformation?"   ‚Üí Answer: "dbt: SQL-based, testable, documented, versioned. Spark: More powerful, handles any data type. We use dbt for SQL transforms, Spark for complex features."      Q: "How do you handle SCD (Slowly Changing Dimensions)?"   ‚Üí Answer: "Type 2 SCD: Track history with effective_date, is_current. Use dbt snapshots. Or use merge strategy for updates. Depends on use case."3. **Design Decisions:**   - Why dbt over pure SQL? ‚Üí Testing, documentation, version control, dependency management   - Why 3 layers? ‚Üí Clear separation, maintainability, reusability   - Why incremental? ‚Üí Performance, only process new data   - Why PostgreSQL for dbt? ‚Üí SQL compatibility, ACID transactions, dbt native support4. **What-If Scenarios:**   - "What if dbt test fails?" ‚Üí Answer: Investigation, fix source data or dbt logic, re-run   - "What if schema changes?" ‚Üí Answer: Update dbt models, version control, gradual rollout   - "What if incremental breaks?" ‚Üí Answer: Full refresh, check merge logic, fix and re-run   - "What if model is slow?" ‚Üí Answer: Optimize SQL, add indexes, use incremental, partition   - "What if dependency issue?" ‚Üí Answer: Check dbt lineage, fix model order, use ref() correctly5. **Code Quality:**   - Clean SQL with comments   - Reusable macros (Jinja)   - Comprehensive tests   - Good documentationPlease provide complete dbt project with all models, tests, and documentation.
üéØ TOPIC 7: FastAPI REST API

I'm working on Topic 7: FastAPI REST API.
Reference: Learning Guide.txt - Topic 7 and Layer 6 architecture

**NOTE**: Follow the same comprehensive format as Topic 2:
- Real-world challenges (API timeouts, DB connection issues, caching problems, rate limiting)
- WHY/WHAT/HOW TO/WHAT IF explanations
- Comprehensive interview Q&A
- Learning-by-doing exercises
- Modern practices (API versioning, rate limiting, caching strategies)

Please help me implement:1. **FastAPI Project Setup:**   - Create FastAPI application   - Configure CORS   - Set up logging   - Environment variables for DB connection2. **3 Core Endpoints:**   **GET /sensors**   - List all sensors with latest readings   - Query parameters:     * location (optional): Filter by city     * status (optional): active/inactive/faulty     * limit (optional): Pagination   - Response: List of sensors with latest temperature, humidity, timestamp   - Cache: 1 minute TTL   **GET /analytics/{sensor_id}**   - Get analytics for specific sensor   - Path parameter: sensor_id (required)   - Query parameters:     * start_date (required): YYYY-MM-DD     * end_date (required): YYYY-MM-DD     * granularity (optional): hourly/daily (default: daily)   - Response: Time series data with avg, max, min temperature   - Cache: 5 minutes TTL   **GET /health**   - Health check endpoint   - Check: Database connection, latest data timestamp, recent failures   - Response: Overall health status3. **Request/Response Validation:**   - Use Pydantic models for validation   - Validate date ranges (start <= end, max 90 days)   - Validate sensor_id format   - Type hints for all models4. **Error Handling:**   - 400: Invalid parameters   - 404: Sensor not found   - 500: Server errors   - Consistent error response format   - Request ID for debugging5. **Database Queries:**   - Read from PostgreSQL only (read-only operations)   - Optimized queries with indexes   - Connection pooling   - Query timeouts6. **API Documentation:**   - Auto-generated Swagger UI (/docs)   - ReDoc (/redoc)   - Include examples**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why FastAPI? (Async, auto-docs, type hints, fast)   - Why Pydantic? (Validation, type safety, auto-docs)   - Why caching? (Reduce DB load, faster responses)   - Why read-only from PostgreSQL? (MongoDB for writes, PostgreSQL for queries)2. **Interview Questions - Prepare Answers:**      Q: "Design a REST API for querying data"   ‚Üí Answer: "FastAPI with 3 endpoints: /sensors (list), /analytics/{id} (time series), /health (status). Pydantic validation, caching, error handling, auto-docs."      Q: "Request validation?"   ‚Üí Answer: "Pydantic models validate input. Check types, ranges, formats. Return 400 with clear error messages if invalid. Prevents bad queries."      Q: "Error handling?"   ‚Üí Answer: "Consistent error format with status code, error code, message. 400 for bad input, 404 for not found, 500 for server errors. Request ID for debugging."      Q: "Pagination strategy?"   ‚Üí Answer: "Limit + offset for simple pagination. For large datasets, use cursor-based (last_id). We use limit for now, can upgrade to cursor if needed."      Q: "API versioning?"   ‚Üí Answer: "URL versioning: /v1/sensors. Or header versioning. We use /v1/ prefix. Allows breaking changes in v2 without affecting v1 clients."3. **Design Decisions:**   - Why FastAPI over Flask? ‚Üí Async, auto-docs, type hints, better performance   - Why REST over GraphQL? ‚Üí Simpler, caching friendly, sufficient for our needs   - Why caching? ‚Üí Reduce DB load, faster responses for repeated queries   - Why read-only? ‚Üí Separation: MongoDB writes, PostgreSQL reads4. **What-If Scenarios:**   - "What if API gets 1000 requests/sec?" ‚Üí Answer: Add load balancer, scale horizontally, increase caching, optimize queries   - "What if database is slow?" ‚Üí Answer: Add indexes, optimize queries, increase connection pool, use read replicas   - "What if cache is stale?" ‚Üí Answer: Reduce TTL, use cache invalidation, or accept slight staleness for performance   - "What if sensor_id doesn't exist?" ‚Üí Answer: Return 404 with clear message, don't expose internal errors   - "What if date range too large?" ‚Üí Answer: Limit to 90 days, return 400 if exceeded, suggest smaller range5. **Code Quality:**   - Type hints everywhere   - Comprehensive error handling   - Logging for debugging   - Unit tests for endpointsPlease provide complete FastAPI application with all endpoints, validation, and error handling.
üéØ TOPIC 8: Orchestration with Airflow

I'm working on Topic 8: Orchestration with Airflow.
Reference: Learning Guide.txt - Topic 8 and Layer 7 architecture

**NOTE**: Follow the same comprehensive format as Topic 2:
- Real-world challenges (DAG failures, task retries, dependency issues, backfill problems)
- WHY/WHAT/HOW TO/WHAT IF explanations
- Comprehensive interview Q&A
- Learning-by-doing exercises
- Modern practices (Airflow 2.0+, cloud deployment, observability)

Please help me implement:1. **Airflow Setup:**   - Configure LocalExecutor   - Set up PostgreSQL as metadata database   - Configure DAGs folder   - Set up logging2. **3 DAGs:**   **DAG 1: ingestion_validation_dag**   - Schedule: Every 10 minutes   - Tasks:     * check_kafka_health: Verify Kafka is up     * count_messages: Count messages in raw_iot_data (last 10 mins)     * alert_if_low: Alert if < 50 messages (expected 100)   - Retry: 2 times, 5 min interval   - On failure: Alert   **DAG 2: batch_processing_dag**   - Schedule: Daily at 02:00 AM   - Tasks:     * wait_for_data: Verify yesterday's data in PostgreSQL (> 800K rows)     * run_spark_batch: Execute PySpark batch job     * validate_output: Check row count, quality     * update_freshness: Record last successful batch timestamp   - Dependencies: Sequential   - Retry: 1 time, 30 min interval   - On failure: Alert, manual investigation   **DAG 3: transformation_dag**   - Schedule: Daily at 03:00 AM   - Depends on: batch_processing_dag success   - Tasks:     * dbt_seed: Load device_metadata     * dbt_run: Execute all dbt models     * dbt_test: Run quality tests     * generate_docs: Update documentation   - Retry: Don't retry on test failure (indicates real issue)   - On failure: Alert, require manual fix3. **Task Dependencies:**   - Use >> operator for dependencies   - Set trigger rules (all_success, all_failed, etc.)   - Handle upstream failures4. **Error Handling:**   - Retry logic with exponential backoff   - Email/Slack alerts on failure   - XCom for task communication (optional)   - Task timeouts5. **Monitoring:**   - Track DAG run history   - Monitor task durations   - Alert on failures   - Dashboard for pipeline health**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why Airflow? (Open source, mature, good UI, scheduling)   - Why 3 DAGs? (Separation: ingestion, batch, transformation)   - Why dependencies? (Ensure correct order, don't waste resources)   - Why retries? (Handle transient failures)2. **Interview Questions - Prepare Answers:**      Q: "How do you orchestrate data pipelines?"   ‚Üí Answer: "Airflow DAGs schedule tasks. 3 DAGs: ingestion (every 10 min), batch (daily 2 AM), transformation (daily 3 AM). Dependencies ensure correct order."      Q: "Handling DAG failures?"   ‚Üí Answer: "Retry logic (2-3 times). Alert on persistent failures. Manual investigation required. Don't retry on data quality failures (indicates real issue)."      Q: "Task dependencies?"   ‚Üí Answer: "Use >> operator. Sequential: task1 >> task2. Parallel: [task1, task2] >> task3. Trigger rules handle upstream failures."      Q: "Scheduling complex workflows?"   ‚Üí Answer: "Cron expressions for schedules. Dependencies for order. Conditional logic for branching. XCom for data passing between tasks."      Q: "Monitoring pipeline health?"   ‚Üí Answer: "Airflow UI shows DAG status. Track success rate, duration, failures. Alert on anomalies. Health endpoint in API."3. **Design Decisions:**   - Why Airflow over cron? ‚Üí Dependency management, retries, monitoring, UI   - Why Airflow over Prefect? ‚Üí More mature, larger community, better for learning   - Why 3 separate DAGs? ‚Üí Clear separation, independent scheduling, easier debugging   - Why LocalExecutor? ‚Üí Simple for learning, sufficient for small scale4. **What-If Scenarios:**   - "What if DAG fails at 2 AM?" ‚Üí Answer: Retry automatically, alert if persists, manual investigation, may need to backfill   - "What if batch job takes 2 hours?" ‚Üí Answer: Optimize job, increase resources, set timeout, alert if exceeds threshold   - "What if dbt test fails?" ‚Üí Answer: Don't retry (real issue), alert, investigate data quality, fix and manually re-run   - "What if upstream task fails?" ‚Üí Answer: Downstream tasks skip (trigger_rule), alert, fix upstream, re-run   - "What if need to backfill?" ‚Üí Answer: Use Airflow backfill command, process historical dates, monitor progress5. **Code Quality:**   - Clean DAG definitions   - Reusable operators   - Good error messages   - Documentation in DAGsPlease provide complete Airflow DAGs with all tasks, dependencies, and error handling.
üéØ TOPIC 9: Monitoring, Logging & Alerts

I'm working on Topic 9: Monitoring, Logging & Alerts.
Reference: Learning Guide.txt - Topic 9 and Layer 8 architecture

**NOTE**: Follow the same comprehensive format as Topic 2:
- Real-world challenges (alert fatigue, log volume, metric accuracy, performance impact)
- WHY/WHAT/HOW TO/WHAT IF explanations
- Comprehensive interview Q&A
- Learning-by-doing exercises
- Modern practices (Grafana, Prometheus, ELK, distributed tracing)

Please help me implement:1. **Structured Logging:**   - JSON format logging   - Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL   - Include: timestamp, level, service, task, message, context   - Write to both file and console2. **Key Metrics to Track:**   - Data freshness: Latest data timestamp (alert if > 5 min old)   - Throughput: Messages/min entering Kafka (expected 600)   - Quality: % valid records (alert if < 95%)   - Processing latency: Time from Kafka to DB (alert if > 60 sec)   - Job success rate: % DAG runs succeeding (alert if < 95%)   - Storage usage: DB size, DLQ size (alert if growing fast)   - Error rate: Count of critical errors (alert if spike)3. **Alerting Logic:**   - Alert if data freshness > 5 minutes (HIGH severity)   - Alert if quality < 95% (HIGH severity)   - Alert if DAG fails (HIGH severity)   - Alert if throughput < 500 msgs/min (MEDIUM severity)   - Alert if DLQ size > 1 GB (MEDIUM severity)   - Alert if API error rate > 5% (MEDIUM severity)   - Send alerts to console/log (Slack integration optional)4. **Health Endpoint:**   - Add to FastAPI: GET /health   - Check: Database connection, latest data timestamp, recent failures   - Return: Overall health status with details5. **Metrics Collection:**   - Log metrics to file (JSON)   - Aggregate daily metrics   - Create metrics dashboard (optional: Grafana)**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why structured logging? (Machine-readable, easy to parse, searchable)   - Why JSON format? (Standard, parseable, supports nested data)   - Why multiple log levels? (Filter by severity, reduce noise)   - Why metrics + logs? (Metrics = trends, Logs = details)2. **Interview Questions - Prepare Answers:**      Q: "How do you monitor production pipelines?"   ‚Üí Answer: "Structured logging (JSON), key metrics (freshness, quality, latency), alerts on thresholds, health endpoints, daily dashboards."      Q: "What metrics matter?"   ‚Üí Answer: "Data freshness (< 5 min), quality (> 95%), throughput (600 msgs/min), latency (< 60 sec), success rate (> 95%). Business-focused metrics."      Q: "How do you detect issues?"   ‚Üí Answer: "Alerts on thresholds, log analysis for patterns, metrics trends, health checks. Proactive monitoring before users notice."      Q: "Setting up alerts?"   ‚Üí Answer: "Threshold-based alerts (freshness > 5 min, quality < 95%). Severity levels (HIGH/MEDIUM). Don't alert on every minor issue."      Q: "Debugging production issues?"   ‚Üí Answer: "Check logs with request_id, trace through services, check metrics for anomalies, use health endpoints, correlate timestamps."3. **Design Decisions:**   - Why structured logging? ‚Üí Machine-readable, easy to search, supports tools   - Why JSON? ‚Üí Standard format, nested data, widely supported   - Why multiple alert levels? ‚Üí Prioritize critical issues, reduce noise   - Why health endpoint? ‚Üí Quick status check, load balancer integration4. **What-If Scenarios:**   - "What if logs fill disk?" ‚Üí Answer: Log rotation, retention policy (30 days), archive old logs   - "What if too many alerts?" ‚Üí Answer: Tune thresholds, aggregate alerts, use alert fatigue prevention   - "What if metrics are wrong?" ‚Üí Answer: Validate metrics, check collection logic, compare with logs   - "What if can't find issue?" ‚Üí Answer: Add more logging, increase log levels, use distributed tracing   - "What if alert doesn't fire?" ‚Üí Answer: Test alerts regularly, monitor alert system itself, have backup channels5. **Code Quality:**   - Consistent logging format   - Configurable thresholds   - Comprehensive error context   - Performance (don't slow down pipeline)Please provide complete monitoring setup with logging, metrics, and alerting.
üéØ TOPIC 10: Docker & Containerization

I'm working on Topic 10: Docker & Containerization.
Reference: Learning Guide.txt - Topic 10 and Layer 10 architecture

**NOTE**: Follow the same comprehensive format as Topic 2:
- Real-world challenges (container crashes, volume issues, network problems, build failures)
- WHY/WHAT/HOW TO/WHAT IF explanations
- Comprehensive interview Q&A
- Learning-by-doing exercises
- Modern practices (multi-stage builds, security scanning, Kubernetes)

Please help me implement:1. **Dockerfiles for Each Component:**      **Dockerfile.data_generator:**   - Base: Python 3.11   - Install: kafka-python, faker   - Copy: generator code   - CMD: Run generator   **Dockerfile.spark:**   - Base: Apache Spark image   - Install: Python dependencies   - Copy: Spark job code   - Configure: Spark settings   **Dockerfile.api:**   - Base: Python 3.11   - Install: FastAPI, uvicorn, psycopg2   - Copy: API code   - Expose: Port 8000   - CMD: Run uvicorn   **Dockerfile.airflow:**   - Base: Apache Airflow image   - Install: Additional dependencies   - Copy: DAGs, plugins   - Configure: Airflow settings2. **docker-compose.yml:**   - Services:     * MongoDB (port 27017)     * PostgreSQL (port 5432)     * Kafka KRaft mode (port 9092)     * Data Generator     * Spark Streaming     * Spark Batch (scheduled)     * Airflow (webserver 8080, scheduler)     * FastAPI (port 8000)   - Networks: iot_network   - Volumes: Data persistence   - Environment variables: .env file   - Health checks: For all services   - Dependencies: Proper startup order3. **Environment Management:**   - .env file for local development   - .env.example template   - Secrets management (don't commit passwords)4. **Volume Mounting:**   - MongoDB data: /data/db   - PostgreSQL data: /var/lib/postgresql/data   - Kafka logs: /var/kafka-logs   - Airflow logs: ./airflow/logs   - Code mounting: For development (hot reload)5. **Network Configuration:**   - Bridge network: iot_network   - Service discovery: Use service names   - Port mapping: Expose necessary ports**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why Docker? (Reproducibility, isolation, easy deployment)   - Why Docker Compose? (Orchestrate multiple services, single command)   - Why volumes? (Data persistence across restarts)   - Why health checks? (Ensure services ready before dependencies start)2. **Interview Questions - Prepare Answers:**      Q: "How do you containerize applications?"   ‚Üí Answer: "Dockerfile for each service. Multi-stage builds for optimization. Use official base images. Copy code, install dependencies, set CMD."      Q: "Docker vs local development?"   ‚Üí Answer: "Docker: Consistent environment, easy setup, production-like. Local: Faster iteration, easier debugging. Use Docker for deployment, local for dev."      Q: "Docker Compose benefits?"   ‚Üí Answer: "Orchestrate multiple services, single command (docker-compose up), network isolation, volume management, dependency handling."      Q: "Managing secrets in containers?"   ‚Üí Answer: "Environment variables from .env (not in image), secrets manager in production, don't commit passwords, use Docker secrets for sensitive data."      Q: "Deploying to production?"   ‚Üí Answer: "Build images, push to registry, use Kubernetes or ECS for orchestration, use managed services (RDS, MSK), CI/CD pipeline."3. **Design Decisions:**   - Why Docker Compose over Kubernetes? ‚Üí Simpler for learning, sufficient for small scale   - Why separate Dockerfiles? ‚Üí Different dependencies, optimization, maintainability   - Why volumes? ‚Üí Data persistence, don't lose data on restart   - Why health checks? ‚Üí Ensure services ready, proper startup order4. **What-If Scenarios:**   - "What if container crashes?" ‚Üí Answer: Restart policy, health checks, monitoring, alert   - "What if out of disk space?" ‚Üí Answer: Monitor volumes, clean old data, increase disk, use external storage   - "What if network issues?" ‚Üí Answer: Check network config, service discovery, DNS resolution, firewall rules   - "What if build fails?" ‚Üí Answer: Check Dockerfile, dependencies, base image, build context   - "What if performance issues?" ‚Üí Answer: Optimize images (multi-stage), resource limits, profiling, scaling5. **Code Quality:**   - Optimized Dockerfiles (multi-stage, layer caching)   - Proper .dockerignore   - Good documentation   - Security best practicesPlease provide complete Docker setup with all Dockerfiles and docker-compose.yml.
üéØ TOPIC 11: GitHub & CI/CD Basics

I'm working on Topic 11: GitHub & CI/CD Basics.
Reference: Learning Guide.txt - Topic 11

**NOTE**: Follow the same comprehensive format as Topic 2:
- Real-world challenges (pipeline failures, test flakiness, deployment issues, rollback scenarios)
- WHY/WHAT/HOW TO/WHAT IF explanations
- Comprehensive interview Q&A
- Learning-by-doing exercises
- Modern practices (GitHub Actions, test automation, security scanning)

Please help me implement:1. **GitHub Repository Setup:**   - Initialize repository   - Create .gitignore (Python, Docker, IDE, env files)   - Set up branch strategy:     * main: Production-ready code     * develop: Integration branch     * feature/*: Feature branches   - Initial commit with project structure2. **README.md:**   - Project overview (100 sensors, 864K readings/day)   - Architecture diagram (ASCII text)   - Setup instructions:     * Prerequisites     * Installation steps     * How to run (docker-compose up)   - Project structure explanation   - API documentation   - Contributing guidelines3. **GitHub Actions Workflow:**   - File: .github/workflows/ci.yml   - Triggers: On push to main, on PR   - Jobs:     * Lint: Run Python linter (flake8, black)     * Test: Run unit tests (pytest)     * Build: Build Docker images     * Security: Scan for vulnerabilities   - Fail fast: Stop on first failure4. **Code Quality:**   - .pre-commit-config.yaml (optional)   - Linting: flake8, black   - Type checking: mypy (optional)   - Test coverage: pytest-cov5. **Documentation:**   - Architecture docs   - API docs (auto-generated from FastAPI)   - Setup guide   - Troubleshooting guide**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why Git? (Version control, collaboration, history)   - Why GitHub? (Hosting, CI/CD, collaboration)   - Why branch strategy? (Isolation, code review, stability)   - Why CI/CD? (Automated testing, catch issues early)2. **Interview Questions - Prepare Answers:**      Q: "Show me your project on GitHub"   ‚Üí Answer: "Well-organized repo with README, clear structure, CI/CD pipeline, good commit history, documentation. Shows professional approach."      Q: "Code organization?"   ‚Üí Answer: "Modular structure: data_generator, spark_streaming, api, etc. Each component isolated. Clear separation of concerns. Easy to navigate."      Q: "CI/CD pipeline?"   ‚Üí Answer: "GitHub Actions: Lint on PR, run tests, build Docker images, security scan. Automated quality checks before merge."      Q: "Testing strategy?"   ‚Üí Answer: "Unit tests for each component, integration tests for pipeline, test data quality, test API endpoints. Run in CI/CD."      Q: "Git workflow?"   ‚Üí Answer: "Feature branches, PR for review, merge to develop, then main. Clean commit history. Meaningful commit messages."3. **Design Decisions:**   - Why GitHub over GitLab? ‚Üí More popular, better integration, easier for portfolio   - Why GitHub Actions over Jenkins? ‚Üí Simpler, integrated, free for public repos   - Why branch strategy? ‚Üí Code review, isolation, stability   - Why CI/CD? ‚Üí Catch issues early, automated testing, confidence in deployments4. **What-If Scenarios:**   - "What if CI fails?" ‚Üí Answer: Fix issues, don't merge, investigate, update tests   - "What if merge conflict?" ‚Üí Answer: Rebase, resolve conflicts, test, then merge   - "What if forgot to commit?" ‚Üí Answer: Add to next commit, use git add, commit with clear message   - "What if broke production?" ‚Üí Answer: Rollback, fix in hotfix branch, test, deploy   - "What if need to revert?" ‚Üí Answer: Use git revert (safe) or reset (destructive), test, deploy5. **Code Quality:**   - Clean commit history   - Meaningful commit messages   - Good documentation   - Professional READMEPlease provide complete GitHub setup with README, CI/CD workflow, and documentation.
üéØ TOPIC 12: Project Walkthrough & Interview Prep

I'm working on Topic 12: Project Walkthrough & Interview Prep.
Reference: Learning Guide.txt - Topic 12

**NOTE**: This topic consolidates all previous topics with:
- Complete project walkthrough
- Comprehensive interview Q&A covering all topics
- Real-world challenges across entire pipeline
- System design scenarios
- Presentation preparation

Please help me prepare:1. **15-Minute Project Presentation:**   - Architecture overview (2 min)   - Key decisions & trade-offs (3 min)   - Challenges & solutions (3 min)   - Scalability considerations (2 min)   - What you'd do differently (2 min)   - Demo (3 min)2. **Key Decisions Documentation:**   - Why Kafka? (High throughput, durability, partitioning)   - Why MongoDB + PostgreSQL? (Write vs Read optimization)   - Why KRaft? (Modern, simpler, no Zookeeper)   - Why Spark Streaming? (Flexibility, ML integration)   - Why dbt? (Testing, documentation, SQL-based)   - Why Airflow? (Mature, good UI, scheduling)   - Why FastAPI? (Async, auto-docs, fast)3. **Trade-offs Documented:**   - Spark Streaming vs Kafka Streams   - Real-time vs Batch (when to use each)   - dbt vs Spark for transformation   - Airflow vs Prefect vs Dagster   - MongoDB + PostgreSQL vs Single DB   - KRaft vs Zookeeper4. **Cost Estimation:**   - Hardware requirements   - Storage per month (MongoDB + PostgreSQL)   - Compute cost (Spark, Airflow)   - Network cost   - Optimization opportunities5. **20 Scenario Questions - Prepare Answers:**   - "What if Kafka goes down?"   - "How would you handle 10x data volume?"   - "Optimize this slow query"   - "Handle schema change"   - "What if MongoDB fails?"   - "What if PostgreSQL fails?"   - "How to scale to 1M sensors?"   - "What if data quality drops?"   - "How to reduce costs?"   - "What if need real-time ML predictions?"   - And 10 more scenarios...**INTERVIEW PREPARATION - Please also provide:**1. **Presentation Structure:**   - Opening (30 sec): Problem statement, solution overview   - Architecture (2 min): 10 layers, data flow   - Decisions (3 min): Why each technology, trade-offs   - Challenges (3 min): Problems faced, solutions   - Scalability (2 min): How to scale, optimizations   - Demo (3 min): Show working system   - Closing (30 sec): Key takeaways, learnings2. **Interview Questions - Comprehensive Answers:**      Q: "Walk me through your project"   ‚Üí Answer: "IoT pipeline: 100 sensors ‚Üí Kafka ‚Üí Spark Streaming (real-time) + Batch ‚Üí MongoDB (write) ‚Üí PostgreSQL (read) ‚Üí FastAPI ‚Üí Dashboards. End-to-end with monitoring."      Q: "Why these design choices?"   ‚Üí Answer: "Kafka for high throughput. MongoDB for writes, PostgreSQL for reads (optimization). Spark for flexibility. dbt for SQL transforms. Airflow for orchestration."      Q: "How would you scale it?"   ‚Üí Answer: "Horizontal scaling: More Kafka partitions, Spark cluster, DB replicas. Vertical: Increase resources. Optimize: Partitioning, caching, indexing."      Q: "What would you improve?"   ‚Üí Answer: "Add ML for anomaly detection, real-time dashboards, data lake for archival, better monitoring (Grafana), automated testing, disaster recovery."3. **Scenario Answers - Detailed:**   - For each of 20 scenarios, provide:     * Problem identification     * Solution approach     * Implementation steps     * Trade-offs     * Monitoring4. **Common Pitfalls to Avoid:**   - Don't over-engineer   - Don't claim to handle billion rows   - Don't say you'd use everything   - Be honest about limitations   - Show learning mindset5. **Portfolio Tips:**   - Clean GitHub repo   - Good README   - Architecture diagrams   - Demo video (optional)   - Blog post (optional)Please provide comprehensive interview prep material with all answers, scenarios, and presentation structure.
üìù HOW TO USE THESE PROMPTS
================================================================================

**For Each Topic:**

1. **Copy the topic prompt** from Learning Guide.txt
2. **Paste into Cursor AI** with this instruction:
   ```
   "I'm working on [Topic X]. Please implement it following the Learning Guide.txt guidelines.
   
   For this topic, I need:
   - Real-world data engineering challenges you face daily
   - Comprehensive WHY, WHAT, HOW TO, WHAT IF explanations
   - Interview preparation with detailed Q&A
   - Learning-by-doing exercises
   - Modern data engineering practices"
   ```

3. **Cursor AI will provide:**
   - ‚úÖ Complete code implementation
   - ‚úÖ Real-world problem scenarios
   - ‚úÖ Detailed explanations (WHY, WHAT, HOW TO, WHAT IF)
   - ‚úÖ Interview Q&A with answers
   - ‚úÖ Hands-on exercises
   - ‚úÖ Production best practices

4. **After implementation:**
   - Review the code
   - Practice the interview answers
   - Complete the learning exercises
   - Test the what-if scenarios
   - Understand the real-world challenges
   - Move to next topic

**Learning Approach:**
- ‚ùå Don't just copy code - understand WHY
- ‚úÖ Practice explaining concepts (teach-back method)
- ‚úÖ Work through the exercises
- ‚úÖ Think about edge cases
- ‚úÖ Prepare for interview questions
- ‚úÖ Understand real-world problems
- ‚úÖ Learn from common mistakes

**For Interview Preparation:**
- Practice explaining each concept in your own words
- Work through all scenario questions
- Understand trade-offs and alternatives
- Be ready to discuss real-world challenges
- Know how to debug and troubleshoot
- Understand scalability and performance

================================================================================
