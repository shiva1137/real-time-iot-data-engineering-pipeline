 COPY-PASTE READY PROMPTS FOR CURSOR AI
IoT Data Engineering Project - All 12 Topics
ðŸŽ¯ TOPIC 1: Project Setup & Architecture
I'm starting Topic 1: Project Setup & Architecture from my IoT Data Engineering Project.Reference: Learning Guide.txt in my workspace (all 5827 lines)Please help me:1. **Create Complete Folder Structure:**   Create the entire project structure following best practices:   
iot-data-pipeline/
â”œâ”€â”€ data_generator/ # Topic 2: Faker data generator
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ generator.py
â”‚ â””â”€â”€ requirements.txt
â”œâ”€â”€ kafka/ # Topic 2: Kafka configs
â”‚ â”œâ”€â”€ topics_config.json
â”‚ â””â”€â”€ init-topics.sh
â”œâ”€â”€ spark_streaming/ # Topic 3: Real-time processing
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ streaming_job.py
â”‚ â””â”€â”€ requirements.txt
â”œâ”€â”€ spark_batch/ # Topic 4: Daily batch jobs
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ batch_job.py
â”‚ â””â”€â”€ requirements.txt
â”œâ”€â”€ data_quality/ # Topic 5: Validation logic
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ validators.py
â”‚ â””â”€â”€ requirements.txt
â”œâ”€â”€ dbt/ # Topic 6: dbt project
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â”œâ”€â”€ staging/
â”‚ â”‚ â”œâ”€â”€ intermediate/
â”‚ â”‚ â””â”€â”€ marts/
â”‚ â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ dbt_project.yml
â”‚ â””â”€â”€ profiles.yml
â”œâ”€â”€ api/ # Topic 7: FastAPI
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ routes/
â”‚ â””â”€â”€ requirements.txt
â”œâ”€â”€ airflow/ # Topic 8: DAGs
â”‚ â”œâ”€â”€ dags/
â”‚ â”œâ”€â”€ logs/
â”‚ â””â”€â”€ plugins/
â”œâ”€â”€ monitoring/ # Topic 9: Logs, alerts
â”‚ â”œâ”€â”€ logging_config.py
â”‚ â””â”€â”€ alerts.py
â”œâ”€â”€ docker/ # Topic 10: Dockerfiles
â”‚ â”œâ”€â”€ Dockerfile.generator
â”‚ â”œâ”€â”€ Dockerfile.spark
â”‚ â”œâ”€â”€ Dockerfile.api
â”‚ â””â”€â”€ docker-compose.yml
â”œâ”€â”€ .github/ # Topic 11: CI/CD
â”‚ â””â”€â”€ workflows/
â”‚ â””â”€â”€ ci.yml
â”œâ”€â”€ docs/ # Documentation
â”‚ â””â”€â”€ architecture.md
â”œâ”€â”€ scripts/ # Utility scripts
â”‚ â””â”€â”€ setup.sh
â”œâ”€â”€ tests/ # Test files
â”‚ â””â”€â”€ init.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
2. **Initialize Git Repository:**   - Create .gitignore for Python, Docker, IDE files, environment variables   - Initialize git repository   - Create initial commit message3. **Create docker-compose.yml:**   - MongoDB service (port 27017)   - PostgreSQL service (port 5432)   - Kafka service (KRaft mode, port 9092) - NO Zookeeper   - Network configuration (iot_network)   - Volume mounts for persistence   - Environment variables setup4. **Create README.md:**   - Project overview (100 sensors, 864K readings/day)   - Architecture diagram (ASCII text-based)   - Setup instructions   - How to run: docker-compose up   - Project structure explanation5. **Create .env.example:**   - Template for MongoDB, PostgreSQL, Kafka connection strings   - All environment variables with comments6. **Create requirements.txt:**   - Placeholder with comments for future dependencies**INTERVIEW PREPARATION - Please also provide:**1. **Architecture Explanation:**   - Why this folder structure? (Separation of concerns, scalability)   - How does data flow through the system?   - Why Docker Compose? (Local development, reproducibility)2. **Design Decisions - Answer These:**   - "Why did you choose Kafka over RabbitMQ/RabbitMQ/Redis?"     â†’ Provide answer: High throughput, durability, partitioning   - "Why MongoDB + PostgreSQL instead of just one?"     â†’ Provide answer: MongoDB for writes (high volume), PostgreSQL for reads (SQL queries)   - "Why KRaft instead of Zookeeper?"     â†’ Provide answer: Modern approach, simpler, no external dependency   - "How do you handle data flow?"     â†’ Provide answer: Kafka â†’ Spark Streaming/Batch â†’ MongoDB (write) â†’ PostgreSQL (read) â†’ API3. **What-If Scenarios - Prepare Answers:**   - "What if Kafka goes down?" â†’ Answer: Producer retries, data buffered, DLQ for failures   - "What if MongoDB fails?" â†’ Answer: Write failures logged, retry mechanism, alert triggered   - "What if PostgreSQL fails?" â†’ Answer: Read operations fail, but writes continue to MongoDB   - "How would you scale this?" â†’ Answer: Horizontal scaling, more partitions, distributed Spark4. **Code Quality:**   - Follow Python best practices   - Add comments explaining architecture decisions   - Include docstringsPlease create all files and explain the structure. I want to understand why each folder/file is needed.
ðŸŽ¯ TOPIC 2: Data Ingestion with Kafka
I'm working on Topic 2: Data Ingestion with Kafka.Reference: Learning Guide.txt - Topic 2 section and Layer 1 architecturePlease help me implement:1. **Kafka Broker Setup (KRaft Mode):**   - Update docker-compose.yml with Kafka in KRaft mode (no Zookeeper)   - Configure KRaft-specific environment variables   - Create init script to auto-create topics:     * raw_iot_data (3 partitions)     * validated_iot_data (3 partitions)     * dlq_iot_data (1 partition for dead-letter queue)2. **Faker Data Generator:**   - Build Python script that simulates 100 IoT sensors   - Generate realistic data:     * sensor_id, location, device_type     * temperature (-5 to 45Â°C with realistic variation)     * humidity (20-80%)     * energy_consumption (0.5-5 kWh)     * timestamp, signal_strength, battery_level   - Send data every 10 seconds per sensor   - Add random failures (5% chance) to simulate real-world issues3. **Kafka Producer Implementation:**   - Use kafka-python library   - Implement idempotent producer (enable.idempotence=true)   - Partitioning strategy: hash(sensor_id) % 3   - Error handling:     * Retry with exponential backoff (5s â†’ 10s â†’ 20s)     * Log failures     * Queue locally if Kafka unavailable   - Add unique message_id for deduplication4. **Validation Consumer:**   - Read from raw_iot_data topic   - Validate:     * Schema (all required fields present)     * Types (temperature is float, timestamp is valid)     * Ranges (temperature -50 to 50Â°C, humidity 0-100%)     * Freshness (timestamp < 5 minutes old)     * Duplicates (same sensor_id + timestamp)   - Send valid data to validated_iot_data   - Send invalid data to dlq_iot_data   - Log quality metrics (% valid, % invalid)**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why idempotent producer? (Prevent duplicates on retry)   - Why partition by sensor_id? (Maintain order per sensor)   - Why 3 partitions? (Parallelism without overhead)   - Why DLQ? (Debugging, don't lose failed messages)2. **Interview Questions - Prepare Answers:**      Q: "How do you ingest streaming data?"   â†’ Answer: "We use Kafka as message queue. Producer sends sensor data with idempotency enabled. We partition by sensor_id to maintain order. Validation consumer checks quality and routes to validated topic or DLQ."      Q: "Explain Kafka partitioning"   â†’ Answer: "Partitioning distributes data across brokers. We use hash(sensor_id) so all messages from same sensor go to same partition, maintaining order. 3 partitions allow 3 parallel consumers."      Q: "How do you ensure data reliability?"   â†’ Answer: "Idempotent producer prevents duplicates. acks=all ensures broker confirms write. Retry logic handles transient failures. DLQ captures invalid data for investigation."      Q: "What's an idempotent producer?"   â†’ Answer: "Producer that can safely retry without creating duplicates. Uses unique message_id. If same message sent twice, Kafka deduplicates. Critical for exactly-once semantics."      Q: "How do you handle producer failures?"   â†’ Answer: "Exponential backoff retry (5s, 10s, 20s). Local queue if Kafka down. After 3 retries, log error and alert. Idempotency ensures no duplicates on retry."3. **Design Decisions:**   - Why Kafka over RabbitMQ? â†’ High throughput (600 msgs/min), durability, partitioning   - Why Kafka over Redis? â†’ Persistence, consumer groups, replay capability   - Why exactly-once vs at-least-once? â†’ Exactly-once for analytics accuracy   - Why KRaft over Zookeeper? â†’ Modern, simpler, no external dependency4. **What-If Scenarios:**   - "What if Kafka broker crashes?" â†’ Answer: Producer retries, data queued locally, resumes when Kafka up   - "What if network partition?" â†’ Answer: Producer detects, retries, eventually consistent   - "What if 10x data volume?" â†’ Answer: Add partitions, scale brokers, increase consumer instances   - "What if producer sends duplicate?" â†’ Answer: Idempotency + message_id prevents duplicates   - "What if validation is slow?" â†’ Answer: Parallel consumers, async validation, batch processing5. **Code Quality:**   - Add comprehensive error handling   - Logging with structured format (JSON)   - Unit tests for validation logic   - Configuration via environment variablesPlease provide complete code with detailed comments explaining each concept.
ðŸŽ¯ TOPIC 3: Real-Time Processing with Spark Streaming
I'm working on Topic 3: Real-Time Processing with Spark Streaming.Reference: Learning Guide.txt - Topic 3 and Layer 2 architecturePlease help me implement:1. **Spark Streaming Setup:**   - Configure Spark to consume from Kafka (validated_iot_data topic)   - Use Structured Streaming API   - Set micro-batch interval: 10 seconds   - Enable checkpointing for fault tolerance2. **5-Minute Tumbling Windows:**   - Group data by 5-minute windows   - Window by timestamp column   - Calculate per sensor per window:     * avg_temperature     * max_temperature     * min_temperature     * avg_humidity     * total_energy_consumption     * count (number of readings)3. **Watermarking & Late Data:**   - Set watermark: 1 minute allowed lateness   - Handle late-arriving data:     * If within watermark: Update window result     * If beyond watermark: Drop (too late)   - Use UPDATE output mode (show latest results)4. **State Management:**   - Implement stateful processing with RocksDB   - Store window state across micro-batches   - Cleanup old windows after watermark expires   - Checkpoint state for recovery5. **Output to MongoDB:**   - Write aggregations to MongoDB (write-only)   - Collection: real_time_aggregates   - Update existing windows (overwrite)   - Index on sensor_id + window_start6. **Data Sync to PostgreSQL:**   - Create sync job that reads from MongoDB   - Syncs to PostgreSQL for querying   - Runs every 5 minutes   - Handles conflicts (last write wins)**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why 5-minute windows? (Balance between real-time and efficiency)   - Why watermarking? (Handle late data without infinite state)   - Why UPDATE mode? (Show latest results in dashboards)   - Why RocksDB? (Fast local state, checkpointable)2. **Interview Questions - Prepare Answers:**      Q: "Design a real-time aggregation pipeline"   â†’ Answer: "Spark Streaming consumes from Kafka. Groups by 5-min windows. Calculates aggregations per sensor. Uses watermarking for late data. Writes to MongoDB, synced to PostgreSQL for queries."      Q: "How do you handle late data?"   â†’ Answer: "Watermarking with 1-minute lateness. Data within watermark updates window. Beyond watermark is dropped. Prevents infinite state growth while handling network delays."      Q: "Explain windowing operations"   â†’ Answer: "Tumbling windows: non-overlapping 5-min buckets. Each window aggregates independently. Sliding windows would overlap. Tumbling is simpler and more efficient for our use case."      Q: "What's exactly-once semantics in Spark?"   â†’ Answer: "Each record processed exactly once, even with failures. Achieved via idempotent writes, checkpointing, and transactional output. Prevents duplicate aggregations."      Q: "How do you avoid data loss?"   â†’ Answer: "Checkpointing saves state. If Spark crashes, restarts from checkpoint. Kafka offset tracking ensures no message skipped. Idempotent writes prevent duplicates."      Q: "Spark Streaming vs Kafka Streams?"   â†’ Answer: "Spark Streaming: More flexible, can do complex ML, larger ecosystem. Kafka Streams: Lighter, lower latency, tighter Kafka integration. We chose Spark for flexibility and ML capabilities."3. **Design Decisions:**   - Why Spark Streaming over Kafka Streams? â†’ Flexibility, ML integration, larger ecosystem   - Why 5-min vs 1-min windows? â†’ Balance latency vs computation cost   - Why UPDATE vs APPEND mode? â†’ Dashboards need latest results, not historical logs   - Why MongoDB for writes? â†’ High write throughput, flexible schema4. **What-If Scenarios:**   - "What if Spark crashes mid-window?" â†’ Answer: Restart from checkpoint, reprocess from last committed offset   - "What if data arrives 10 minutes late?" â†’ Answer: Beyond watermark, dropped. Can adjust watermark if needed.   - "What if window computation is slow?" â†’ Answer: Increase parallelism, optimize aggregations, use broadcast joins   - "What if 1000x data volume?" â†’ Answer: Scale Spark cluster, increase partitions, use distributed processing   - "What if watermark too strict?" â†’ Answer: Increase allowed lateness, but trade-off with state size5. **Code Quality:**   - Comprehensive error handling   - Monitoring metrics (processing time, lag)   - Unit tests for windowing logic   - Performance optimization (broadcast joins, caching)Please provide complete code with detailed comments explaining windowing, watermarking, and state management.
ðŸŽ¯ TOPIC 4: Batch Processing with PySpark
I'm working on Topic 4: Batch Processing with PySpark.Reference: Learning Guide.txt - Topic 4 and Layer 3 architecturePlease help me implement:1. **Daily Batch Job:**   - Trigger: Daily at 2 AM (via Airflow later)   - Read all data from PostgreSQL for previous day (synced from MongoDB)   - Process 864K rows efficiently2. **Data Cleaning:**   - Remove duplicates (same sensor_id + timestamp)   - Handle nulls:     * temperature null â†’ drop (critical)     * signal_strength null â†’ fill with average     * humidity null â†’ drop if > 5% missing   - Remove outliers:     * temperature > 50Â°C or < -50Â°C â†’ flag as anomaly   - Type conversions and standardization3. **Hourly Aggregation:**   - Group by sensor_id + hour   - Calculate per hour:     * avg_temperature, max_temp, min_temp     * stddev_temperature (for anomaly detection)     * avg_humidity, max_humidity     * total_energy_consumption     * count of readings   - Result: 100 sensors Ã— 24 hours = 2,400 rows4. **Feature Engineering:**   - 7-day rolling average (look back 7 days)   - Day-over-day % change   - Anomaly flags:     * If temp > 2 Ã— stddev from sensor's mean â†’ flag   - Location statistics:     * Compare sensor to city average     * Rank sensors by temperature     * Hottest/coldest location per hour5. **Optimization:**   - Broadcast join for device_metadata (small table)   - Partition output by date + location   - Cache frequently used DataFrames   - Coalesce small files (1-2 files per partition)6. **Write to MongoDB:**   - Write processed data to MongoDB (write-only)   - Collection: processed_daily   - Index on sensor_id, date, location7. **Sync to PostgreSQL:**   - Sync job reads from MongoDB   - Writes to PostgreSQL for dbt transformations   - Handles schema mapping**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why broadcast join? (Small metadata table, avoids shuffle)   - Why partition by date + location? (Optimizes common queries)   - Why cache? (Reuse DataFrames multiple times)   - Why coalesce? (Fewer files = faster reads)2. **Interview Questions - Prepare Answers:**      Q: "How do you optimize Spark jobs?"   â†’ Answer: "Broadcast small tables, partition by query patterns, cache hot data, coalesce files, use columnar formats, tune executor memory/cores."      Q: "Explain partitioning strategy"   â†’ Answer: "Partition by date + location. Most queries filter by these. Only reads relevant partitions, not entire dataset. Reduces I/O by 90%+."      Q: "Join optimization in Spark"   â†’ Answer: "Broadcast join for small tables (< 100MB). Avoids shuffle. For large tables, use bucketing or sort-merge join. Prefer broadcast when possible."      Q: "How do you handle schema changes?"   â†’ Answer: "Schema evolution in Spark. Add new columns as nullable. Backfill old data. Use mergeSchema option. Version control schema definitions."      Q: "What's the difference between RDD and DataFrame?"   â†’ Answer: "RDD: Low-level, unstructured. DataFrame: High-level, structured, optimized (Catalyst optimizer). We use DataFrame for better performance."      Q: "Caching vs Persisting?"   â†’ Answer: "Cache: Default storage level (memory + disk). Persist: Choose storage level (memory_only, disk_only, etc.). Use persist for fine control."3. **Design Decisions:**   - Why batch vs streaming for features? â†’ Complex features need full history (7-day rolling avg)   - Why PostgreSQL for reads? â†’ SQL queries, dbt compatibility, ACID transactions   - Why MongoDB for writes? â†’ High write throughput, flexible schema   - Why daily vs hourly batch? â†’ Complete data available, less frequent = more efficient4. **What-If Scenarios:**   - "What if job takes 2 hours instead of 15 mins?" â†’ Answer: Optimize joins, increase parallelism, use broadcast, partition better   - "What if out of memory?" â†’ Answer: Increase executor memory, use disk persistence, repartition data   - "What if schema changes?" â†’ Answer: Schema evolution, backfill, version control   - "What if 10x data volume?" â†’ Answer: Scale cluster, increase partitions, optimize aggregations   - "What if join is slow?" â†’ Answer: Broadcast small table, bucket large tables, use sort-merge join5. **Code Quality:**   - Modular functions (cleaning, aggregation, features)   - Configuration via YAML/JSON   - Comprehensive logging   - Unit tests for transformationsPlease provide complete code with optimization explanations and performance tips.
ðŸŽ¯ TOPIC 5: Data Quality & Validation
I'm working on Topic 5: Data Quality & Validation.Reference: Learning Guide.txt - Topic 5 and Layer 4 architecturePlease help me implement:1. **Schema Validation:**   - Validate all required fields present   - Check field types (temperature is float, timestamp is datetime)   - Validate field formats (sensor_id matches pattern "sensor_###")2. **Range Validation:**   - Temperature: -50 to 50Â°C   - Humidity: 0 to 100%   - Energy: 0 to 10 kWh   - Timestamp: Not in future, not > 24 hours old3. **Business Rule Validation:**   - Freshness: timestamp < 5 minutes old   - Anomaly detection: Sudden temp change > 20Â°C (sensor malfunction)   - Duplicate detection: Same sensor_id + timestamp4. **DLQ (Dead-Letter Queue) Handling:**   - Send failed records to dlq_iot_data Kafka topic   - Include failure reason in message   - Store in MongoDB dlq_failed_records collection   - Retention: 7 days5. **Quality Metrics:**   - Track daily:     * % completeness (required fields present)     * % validity (values in range)     * % timeliness (fresh data)     * % uniqueness (no duplicates)   - Log metrics to file (JSON format)   - Alert if quality drops below threshold (> 10% failures)6. **Alerting:**   - Alert if > 10% messages in DLQ   - Alert if quality metric < 95%   - Alert if data freshness > 5 minutes   - Send alerts to console/log (Slack integration optional)**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why validate at ingestion? (Catch issues early, prevent bad data propagation)   - Why DLQ? (Debugging, don't lose failed messages)   - Why multiple validation points? (Defense in depth)   - Why quality metrics? (Track trends, early warning)2. **Interview Questions - Prepare Answers:**      Q: "How do you validate data?"   â†’ Answer: "Multi-layer validation: Schema (fields present, types correct), Range (values in expected range), Business rules (freshness, duplicates). Failed records go to DLQ."      Q: "What quality checks do you implement?"   â†’ Answer: "Completeness (all fields), Validity (in range), Timeliness (< 5 min old), Uniqueness (no duplicates), Consistency (matches patterns). Track metrics daily."      Q: "How do you handle bad data?"   â†’ Answer: "Send to DLQ with failure reason. Log for investigation. Alert if > 10% failures. Manually fix and replay if needed. Prevent propagation downstream."      Q: "Detecting data drift?"   â†’ Answer: "Monitor quality metrics over time. Alert on sudden changes. Track schema changes. Compare distributions. Use statistical tests for anomalies."      Q: "When to alert vs log?"   â†’ Answer: "Alert: > 10% failures, quality < 95%, freshness > 5 min. Log: Individual failures, warnings, debug info. Alert = action needed, Log = investigation."3. **Design Decisions:**   - Why validate at ingestion? â†’ Catch issues early, prevent downstream problems   - Why DLQ vs dropping? â†’ Debugging, understanding failure patterns   - Why multiple thresholds? â†’ Different severity levels (warning vs critical)   - Why 7-day retention? â†’ Enough time for weekly investigation4. **What-If Scenarios:**   - "What if 50% data fails validation?" â†’ Answer: Alert immediately, investigate source, check sensor health, may need recalibration   - "What if validation is slow?" â†’ Answer: Parallel validation, async processing, batch validation   - "What if DLQ fills up?" â†’ Answer: Increase retention, investigate root cause, fix sensors   - "What if false positives?" â†’ Answer: Tune thresholds, review business rules, adjust validation logic   - "What if schema changes?" â†’ Answer: Version validation rules, gradual rollout, backward compatibility5. **Code Quality:**   - Modular validators (schema, range, business rules)   - Configurable thresholds   - Comprehensive error messages   - Unit tests for each validatorPlease provide complete code with validation logic, DLQ handling, and quality metrics tracking.
ðŸŽ¯ TOPIC 6: dbt Transformations
I'm working on Topic 6: dbt Transformations.Reference: Learning Guide.txt - Topic 6 and Layer 5 architecturePlease help me implement:1. **dbt Project Setup:**   - Initialize dbt project   - Configure profiles.yml (PostgreSQL connection)   - Set up dbt_project.yml2. **3-Layer Model Structure:**   **Layer 1: Staging (stg_iot_readings)**   - Read from processed_daily table (PostgreSQL)   - Clean data:     * Rename columns (clarity)     * Convert types (string â†’ float, datetime)     * Remove duplicates     * Remove rows with critical nulls   - Add metadata: _loaded_at, _row_number   **Layer 2: Intermediate (int_iot_with_features)**   - Read from stg_iot_readings   - Join with device_metadata (location, device_type)   - Add time features:     * Extract hour, day, week, month     * Is daytime (7 AM - 6 PM)?     * Is weekend?   - Add calculated columns:     * anomaly_flag (temp > 2Ã—stddev)     * freshness_in_minutes     * sensor_status (Working/Faulty/Recalibration_needed)   **Layer 3: Marts**   - mart_iot_daily_summary:     * Grain: 1 row per sensor per day     * Columns: sensor_id, date, avg_temp, max_temp, min_temp, count   - mart_iot_hourly_summary:     * Grain: 1 row per sensor per hour   - mart_iot_location_stats:     * Grain: 1 row per location per day     * Aggregates across all sensors in location3. **Testing:**   - Unique test: (sensor_id, timestamp) is unique   - Not null tests: sensor_id, temperature, timestamp   - Relationship test: Every sensor_id exists in device_metadata   - Custom test: temperature between -50 and 50   - Freshness test: Data loaded within last 1 hour4. **Documentation:**   - Document each model (purpose, grain)   - Document each column (description, data type)   - Generate data dictionary   - Create lineage diagram5. **Incremental Models:**   - Make daily_summary incremental (only process new dates)   - Use incremental_strategy: merge   - Handle updates vs inserts**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why 3-layer structure? (Separation: clean â†’ enrich â†’ aggregate)   - Why staging first? (Clean raw data before business logic)   - Why marts? (Pre-aggregated for dashboards, fast queries)   - Why incremental? (Only process new data, faster runs)2. **Interview Questions - Prepare Answers:**      Q: "Explain your dbt structure"   â†’ Answer: "3 layers: Staging (clean raw data), Intermediate (add features, joins), Marts (pre-aggregated for analytics). Clear separation, easy to maintain."      Q: "How do you test SQL?"   â†’ Answer: "dbt tests: unique, not_null, relationships, custom SQL. Run `dbt test` after transformations. Fail if any test fails. Ensures data quality."      Q: "What's an incremental model?"   â†’ Answer: "Only processes new data since last run. Uses merge strategy. Faster than full refresh. Critical for large datasets. Tracks last processed date."      Q: "dbt vs Spark for transformation?"   â†’ Answer: "dbt: SQL-based, testable, documented, versioned. Spark: More powerful, handles any data type. We use dbt for SQL transforms, Spark for complex features."      Q: "How do you handle SCD (Slowly Changing Dimensions)?"   â†’ Answer: "Type 2 SCD: Track history with effective_date, is_current. Use dbt snapshots. Or use merge strategy for updates. Depends on use case."3. **Design Decisions:**   - Why dbt over pure SQL? â†’ Testing, documentation, version control, dependency management   - Why 3 layers? â†’ Clear separation, maintainability, reusability   - Why incremental? â†’ Performance, only process new data   - Why PostgreSQL for dbt? â†’ SQL compatibility, ACID transactions, dbt native support4. **What-If Scenarios:**   - "What if dbt test fails?" â†’ Answer: Investigation, fix source data or dbt logic, re-run   - "What if schema changes?" â†’ Answer: Update dbt models, version control, gradual rollout   - "What if incremental breaks?" â†’ Answer: Full refresh, check merge logic, fix and re-run   - "What if model is slow?" â†’ Answer: Optimize SQL, add indexes, use incremental, partition   - "What if dependency issue?" â†’ Answer: Check dbt lineage, fix model order, use ref() correctly5. **Code Quality:**   - Clean SQL with comments   - Reusable macros (Jinja)   - Comprehensive tests   - Good documentationPlease provide complete dbt project with all models, tests, and documentation.
ðŸŽ¯ TOPIC 7: FastAPI REST API
I'm working on Topic 7: FastAPI REST API.Reference: Learning Guide.txt - Topic 7 and Layer 6 architecturePlease help me implement:1. **FastAPI Project Setup:**   - Create FastAPI application   - Configure CORS   - Set up logging   - Environment variables for DB connection2. **3 Core Endpoints:**   **GET /sensors**   - List all sensors with latest readings   - Query parameters:     * location (optional): Filter by city     * status (optional): active/inactive/faulty     * limit (optional): Pagination   - Response: List of sensors with latest temperature, humidity, timestamp   - Cache: 1 minute TTL   **GET /analytics/{sensor_id}**   - Get analytics for specific sensor   - Path parameter: sensor_id (required)   - Query parameters:     * start_date (required): YYYY-MM-DD     * end_date (required): YYYY-MM-DD     * granularity (optional): hourly/daily (default: daily)   - Response: Time series data with avg, max, min temperature   - Cache: 5 minutes TTL   **GET /health**   - Health check endpoint   - Check: Database connection, latest data timestamp, recent failures   - Response: Overall health status3. **Request/Response Validation:**   - Use Pydantic models for validation   - Validate date ranges (start <= end, max 90 days)   - Validate sensor_id format   - Type hints for all models4. **Error Handling:**   - 400: Invalid parameters   - 404: Sensor not found   - 500: Server errors   - Consistent error response format   - Request ID for debugging5. **Database Queries:**   - Read from PostgreSQL only (read-only operations)   - Optimized queries with indexes   - Connection pooling   - Query timeouts6. **API Documentation:**   - Auto-generated Swagger UI (/docs)   - ReDoc (/redoc)   - Include examples**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why FastAPI? (Async, auto-docs, type hints, fast)   - Why Pydantic? (Validation, type safety, auto-docs)   - Why caching? (Reduce DB load, faster responses)   - Why read-only from PostgreSQL? (MongoDB for writes, PostgreSQL for queries)2. **Interview Questions - Prepare Answers:**      Q: "Design a REST API for querying data"   â†’ Answer: "FastAPI with 3 endpoints: /sensors (list), /analytics/{id} (time series), /health (status). Pydantic validation, caching, error handling, auto-docs."      Q: "Request validation?"   â†’ Answer: "Pydantic models validate input. Check types, ranges, formats. Return 400 with clear error messages if invalid. Prevents bad queries."      Q: "Error handling?"   â†’ Answer: "Consistent error format with status code, error code, message. 400 for bad input, 404 for not found, 500 for server errors. Request ID for debugging."      Q: "Pagination strategy?"   â†’ Answer: "Limit + offset for simple pagination. For large datasets, use cursor-based (last_id). We use limit for now, can upgrade to cursor if needed."      Q: "API versioning?"   â†’ Answer: "URL versioning: /v1/sensors. Or header versioning. We use /v1/ prefix. Allows breaking changes in v2 without affecting v1 clients."3. **Design Decisions:**   - Why FastAPI over Flask? â†’ Async, auto-docs, type hints, better performance   - Why REST over GraphQL? â†’ Simpler, caching friendly, sufficient for our needs   - Why caching? â†’ Reduce DB load, faster responses for repeated queries   - Why read-only? â†’ Separation: MongoDB writes, PostgreSQL reads4. **What-If Scenarios:**   - "What if API gets 1000 requests/sec?" â†’ Answer: Add load balancer, scale horizontally, increase caching, optimize queries   - "What if database is slow?" â†’ Answer: Add indexes, optimize queries, increase connection pool, use read replicas   - "What if cache is stale?" â†’ Answer: Reduce TTL, use cache invalidation, or accept slight staleness for performance   - "What if sensor_id doesn't exist?" â†’ Answer: Return 404 with clear message, don't expose internal errors   - "What if date range too large?" â†’ Answer: Limit to 90 days, return 400 if exceeded, suggest smaller range5. **Code Quality:**   - Type hints everywhere   - Comprehensive error handling   - Logging for debugging   - Unit tests for endpointsPlease provide complete FastAPI application with all endpoints, validation, and error handling.
ðŸŽ¯ TOPIC 8: Orchestration with Airflow
I'm working on Topic 8: Orchestration with Airflow.Reference: Learning Guide.txt - Topic 8 and Layer 7 architecturePlease help me implement:1. **Airflow Setup:**   - Configure LocalExecutor   - Set up PostgreSQL as metadata database   - Configure DAGs folder   - Set up logging2. **3 DAGs:**   **DAG 1: ingestion_validation_dag**   - Schedule: Every 10 minutes   - Tasks:     * check_kafka_health: Verify Kafka is up     * count_messages: Count messages in raw_iot_data (last 10 mins)     * alert_if_low: Alert if < 50 messages (expected 100)   - Retry: 2 times, 5 min interval   - On failure: Alert   **DAG 2: batch_processing_dag**   - Schedule: Daily at 02:00 AM   - Tasks:     * wait_for_data: Verify yesterday's data in PostgreSQL (> 800K rows)     * run_spark_batch: Execute PySpark batch job     * validate_output: Check row count, quality     * update_freshness: Record last successful batch timestamp   - Dependencies: Sequential   - Retry: 1 time, 30 min interval   - On failure: Alert, manual investigation   **DAG 3: transformation_dag**   - Schedule: Daily at 03:00 AM   - Depends on: batch_processing_dag success   - Tasks:     * dbt_seed: Load device_metadata     * dbt_run: Execute all dbt models     * dbt_test: Run quality tests     * generate_docs: Update documentation   - Retry: Don't retry on test failure (indicates real issue)   - On failure: Alert, require manual fix3. **Task Dependencies:**   - Use >> operator for dependencies   - Set trigger rules (all_success, all_failed, etc.)   - Handle upstream failures4. **Error Handling:**   - Retry logic with exponential backoff   - Email/Slack alerts on failure   - XCom for task communication (optional)   - Task timeouts5. **Monitoring:**   - Track DAG run history   - Monitor task durations   - Alert on failures   - Dashboard for pipeline health**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why Airflow? (Open source, mature, good UI, scheduling)   - Why 3 DAGs? (Separation: ingestion, batch, transformation)   - Why dependencies? (Ensure correct order, don't waste resources)   - Why retries? (Handle transient failures)2. **Interview Questions - Prepare Answers:**      Q: "How do you orchestrate data pipelines?"   â†’ Answer: "Airflow DAGs schedule tasks. 3 DAGs: ingestion (every 10 min), batch (daily 2 AM), transformation (daily 3 AM). Dependencies ensure correct order."      Q: "Handling DAG failures?"   â†’ Answer: "Retry logic (2-3 times). Alert on persistent failures. Manual investigation required. Don't retry on data quality failures (indicates real issue)."      Q: "Task dependencies?"   â†’ Answer: "Use >> operator. Sequential: task1 >> task2. Parallel: [task1, task2] >> task3. Trigger rules handle upstream failures."      Q: "Scheduling complex workflows?"   â†’ Answer: "Cron expressions for schedules. Dependencies for order. Conditional logic for branching. XCom for data passing between tasks."      Q: "Monitoring pipeline health?"   â†’ Answer: "Airflow UI shows DAG status. Track success rate, duration, failures. Alert on anomalies. Health endpoint in API."3. **Design Decisions:**   - Why Airflow over cron? â†’ Dependency management, retries, monitoring, UI   - Why Airflow over Prefect? â†’ More mature, larger community, better for learning   - Why 3 separate DAGs? â†’ Clear separation, independent scheduling, easier debugging   - Why LocalExecutor? â†’ Simple for learning, sufficient for small scale4. **What-If Scenarios:**   - "What if DAG fails at 2 AM?" â†’ Answer: Retry automatically, alert if persists, manual investigation, may need to backfill   - "What if batch job takes 2 hours?" â†’ Answer: Optimize job, increase resources, set timeout, alert if exceeds threshold   - "What if dbt test fails?" â†’ Answer: Don't retry (real issue), alert, investigate data quality, fix and manually re-run   - "What if upstream task fails?" â†’ Answer: Downstream tasks skip (trigger_rule), alert, fix upstream, re-run   - "What if need to backfill?" â†’ Answer: Use Airflow backfill command, process historical dates, monitor progress5. **Code Quality:**   - Clean DAG definitions   - Reusable operators   - Good error messages   - Documentation in DAGsPlease provide complete Airflow DAGs with all tasks, dependencies, and error handling.
ðŸŽ¯ TOPIC 9: Monitoring, Logging & Alerts
I'm working on Topic 9: Monitoring, Logging & Alerts.Reference: Learning Guide.txt - Topic 9 and Layer 8 architecturePlease help me implement:1. **Structured Logging:**   - JSON format logging   - Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL   - Include: timestamp, level, service, task, message, context   - Write to both file and console2. **Key Metrics to Track:**   - Data freshness: Latest data timestamp (alert if > 5 min old)   - Throughput: Messages/min entering Kafka (expected 600)   - Quality: % valid records (alert if < 95%)   - Processing latency: Time from Kafka to DB (alert if > 60 sec)   - Job success rate: % DAG runs succeeding (alert if < 95%)   - Storage usage: DB size, DLQ size (alert if growing fast)   - Error rate: Count of critical errors (alert if spike)3. **Alerting Logic:**   - Alert if data freshness > 5 minutes (HIGH severity)   - Alert if quality < 95% (HIGH severity)   - Alert if DAG fails (HIGH severity)   - Alert if throughput < 500 msgs/min (MEDIUM severity)   - Alert if DLQ size > 1 GB (MEDIUM severity)   - Alert if API error rate > 5% (MEDIUM severity)   - Send alerts to console/log (Slack integration optional)4. **Health Endpoint:**   - Add to FastAPI: GET /health   - Check: Database connection, latest data timestamp, recent failures   - Return: Overall health status with details5. **Metrics Collection:**   - Log metrics to file (JSON)   - Aggregate daily metrics   - Create metrics dashboard (optional: Grafana)**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why structured logging? (Machine-readable, easy to parse, searchable)   - Why JSON format? (Standard, parseable, supports nested data)   - Why multiple log levels? (Filter by severity, reduce noise)   - Why metrics + logs? (Metrics = trends, Logs = details)2. **Interview Questions - Prepare Answers:**      Q: "How do you monitor production pipelines?"   â†’ Answer: "Structured logging (JSON), key metrics (freshness, quality, latency), alerts on thresholds, health endpoints, daily dashboards."      Q: "What metrics matter?"   â†’ Answer: "Data freshness (< 5 min), quality (> 95%), throughput (600 msgs/min), latency (< 60 sec), success rate (> 95%). Business-focused metrics."      Q: "How do you detect issues?"   â†’ Answer: "Alerts on thresholds, log analysis for patterns, metrics trends, health checks. Proactive monitoring before users notice."      Q: "Setting up alerts?"   â†’ Answer: "Threshold-based alerts (freshness > 5 min, quality < 95%). Severity levels (HIGH/MEDIUM). Don't alert on every minor issue."      Q: "Debugging production issues?"   â†’ Answer: "Check logs with request_id, trace through services, check metrics for anomalies, use health endpoints, correlate timestamps."3. **Design Decisions:**   - Why structured logging? â†’ Machine-readable, easy to search, supports tools   - Why JSON? â†’ Standard format, nested data, widely supported   - Why multiple alert levels? â†’ Prioritize critical issues, reduce noise   - Why health endpoint? â†’ Quick status check, load balancer integration4. **What-If Scenarios:**   - "What if logs fill disk?" â†’ Answer: Log rotation, retention policy (30 days), archive old logs   - "What if too many alerts?" â†’ Answer: Tune thresholds, aggregate alerts, use alert fatigue prevention   - "What if metrics are wrong?" â†’ Answer: Validate metrics, check collection logic, compare with logs   - "What if can't find issue?" â†’ Answer: Add more logging, increase log levels, use distributed tracing   - "What if alert doesn't fire?" â†’ Answer: Test alerts regularly, monitor alert system itself, have backup channels5. **Code Quality:**   - Consistent logging format   - Configurable thresholds   - Comprehensive error context   - Performance (don't slow down pipeline)Please provide complete monitoring setup with logging, metrics, and alerting.
ðŸŽ¯ TOPIC 10: Docker & Containerization
I'm working on Topic 10: Docker & Containerization.Reference: Learning Guide.txt - Topic 10 and Layer 10 architecturePlease help me implement:1. **Dockerfiles for Each Component:**      **Dockerfile.data_generator:**   - Base: Python 3.11   - Install: kafka-python, faker   - Copy: generator code   - CMD: Run generator   **Dockerfile.spark:**   - Base: Apache Spark image   - Install: Python dependencies   - Copy: Spark job code   - Configure: Spark settings   **Dockerfile.api:**   - Base: Python 3.11   - Install: FastAPI, uvicorn, psycopg2   - Copy: API code   - Expose: Port 8000   - CMD: Run uvicorn   **Dockerfile.airflow:**   - Base: Apache Airflow image   - Install: Additional dependencies   - Copy: DAGs, plugins   - Configure: Airflow settings2. **docker-compose.yml:**   - Services:     * MongoDB (port 27017)     * PostgreSQL (port 5432)     * Kafka KRaft mode (port 9092)     * Data Generator     * Spark Streaming     * Spark Batch (scheduled)     * Airflow (webserver 8080, scheduler)     * FastAPI (port 8000)   - Networks: iot_network   - Volumes: Data persistence   - Environment variables: .env file   - Health checks: For all services   - Dependencies: Proper startup order3. **Environment Management:**   - .env file for local development   - .env.example template   - Secrets management (don't commit passwords)4. **Volume Mounting:**   - MongoDB data: /data/db   - PostgreSQL data: /var/lib/postgresql/data   - Kafka logs: /var/kafka-logs   - Airflow logs: ./airflow/logs   - Code mounting: For development (hot reload)5. **Network Configuration:**   - Bridge network: iot_network   - Service discovery: Use service names   - Port mapping: Expose necessary ports**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why Docker? (Reproducibility, isolation, easy deployment)   - Why Docker Compose? (Orchestrate multiple services, single command)   - Why volumes? (Data persistence across restarts)   - Why health checks? (Ensure services ready before dependencies start)2. **Interview Questions - Prepare Answers:**      Q: "How do you containerize applications?"   â†’ Answer: "Dockerfile for each service. Multi-stage builds for optimization. Use official base images. Copy code, install dependencies, set CMD."      Q: "Docker vs local development?"   â†’ Answer: "Docker: Consistent environment, easy setup, production-like. Local: Faster iteration, easier debugging. Use Docker for deployment, local for dev."      Q: "Docker Compose benefits?"   â†’ Answer: "Orchestrate multiple services, single command (docker-compose up), network isolation, volume management, dependency handling."      Q: "Managing secrets in containers?"   â†’ Answer: "Environment variables from .env (not in image), secrets manager in production, don't commit passwords, use Docker secrets for sensitive data."      Q: "Deploying to production?"   â†’ Answer: "Build images, push to registry, use Kubernetes or ECS for orchestration, use managed services (RDS, MSK), CI/CD pipeline."3. **Design Decisions:**   - Why Docker Compose over Kubernetes? â†’ Simpler for learning, sufficient for small scale   - Why separate Dockerfiles? â†’ Different dependencies, optimization, maintainability   - Why volumes? â†’ Data persistence, don't lose data on restart   - Why health checks? â†’ Ensure services ready, proper startup order4. **What-If Scenarios:**   - "What if container crashes?" â†’ Answer: Restart policy, health checks, monitoring, alert   - "What if out of disk space?" â†’ Answer: Monitor volumes, clean old data, increase disk, use external storage   - "What if network issues?" â†’ Answer: Check network config, service discovery, DNS resolution, firewall rules   - "What if build fails?" â†’ Answer: Check Dockerfile, dependencies, base image, build context   - "What if performance issues?" â†’ Answer: Optimize images (multi-stage), resource limits, profiling, scaling5. **Code Quality:**   - Optimized Dockerfiles (multi-stage, layer caching)   - Proper .dockerignore   - Good documentation   - Security best practicesPlease provide complete Docker setup with all Dockerfiles and docker-compose.yml.
ðŸŽ¯ TOPIC 11: GitHub & CI/CD Basics
I'm working on Topic 11: GitHub & CI/CD Basics.Reference: Learning Guide.txt - Topic 11Please help me implement:1. **GitHub Repository Setup:**   - Initialize repository   - Create .gitignore (Python, Docker, IDE, env files)   - Set up branch strategy:     * main: Production-ready code     * develop: Integration branch     * feature/*: Feature branches   - Initial commit with project structure2. **README.md:**   - Project overview (100 sensors, 864K readings/day)   - Architecture diagram (ASCII text)   - Setup instructions:     * Prerequisites     * Installation steps     * How to run (docker-compose up)   - Project structure explanation   - API documentation   - Contributing guidelines3. **GitHub Actions Workflow:**   - File: .github/workflows/ci.yml   - Triggers: On push to main, on PR   - Jobs:     * Lint: Run Python linter (flake8, black)     * Test: Run unit tests (pytest)     * Build: Build Docker images     * Security: Scan for vulnerabilities   - Fail fast: Stop on first failure4. **Code Quality:**   - .pre-commit-config.yaml (optional)   - Linting: flake8, black   - Type checking: mypy (optional)   - Test coverage: pytest-cov5. **Documentation:**   - Architecture docs   - API docs (auto-generated from FastAPI)   - Setup guide   - Troubleshooting guide**INTERVIEW PREPARATION - Please also provide:**1. **Code Explanations:**   - Why Git? (Version control, collaboration, history)   - Why GitHub? (Hosting, CI/CD, collaboration)   - Why branch strategy? (Isolation, code review, stability)   - Why CI/CD? (Automated testing, catch issues early)2. **Interview Questions - Prepare Answers:**      Q: "Show me your project on GitHub"   â†’ Answer: "Well-organized repo with README, clear structure, CI/CD pipeline, good commit history, documentation. Shows professional approach."      Q: "Code organization?"   â†’ Answer: "Modular structure: data_generator, spark_streaming, api, etc. Each component isolated. Clear separation of concerns. Easy to navigate."      Q: "CI/CD pipeline?"   â†’ Answer: "GitHub Actions: Lint on PR, run tests, build Docker images, security scan. Automated quality checks before merge."      Q: "Testing strategy?"   â†’ Answer: "Unit tests for each component, integration tests for pipeline, test data quality, test API endpoints. Run in CI/CD."      Q: "Git workflow?"   â†’ Answer: "Feature branches, PR for review, merge to develop, then main. Clean commit history. Meaningful commit messages."3. **Design Decisions:**   - Why GitHub over GitLab? â†’ More popular, better integration, easier for portfolio   - Why GitHub Actions over Jenkins? â†’ Simpler, integrated, free for public repos   - Why branch strategy? â†’ Code review, isolation, stability   - Why CI/CD? â†’ Catch issues early, automated testing, confidence in deployments4. **What-If Scenarios:**   - "What if CI fails?" â†’ Answer: Fix issues, don't merge, investigate, update tests   - "What if merge conflict?" â†’ Answer: Rebase, resolve conflicts, test, then merge   - "What if forgot to commit?" â†’ Answer: Add to next commit, use git add, commit with clear message   - "What if broke production?" â†’ Answer: Rollback, fix in hotfix branch, test, deploy   - "What if need to revert?" â†’ Answer: Use git revert (safe) or reset (destructive), test, deploy5. **Code Quality:**   - Clean commit history   - Meaningful commit messages   - Good documentation   - Professional READMEPlease provide complete GitHub setup with README, CI/CD workflow, and documentation.
ðŸŽ¯ TOPIC 12: Project Walkthrough & Interview Prep
I'm working on Topic 12: Project Walkthrough & Interview Prep.Reference: Learning Guide.txt - Topic 12Please help me prepare:1. **15-Minute Project Presentation:**   - Architecture overview (2 min)   - Key decisions & trade-offs (3 min)   - Challenges & solutions (3 min)   - Scalability considerations (2 min)   - What you'd do differently (2 min)   - Demo (3 min)2. **Key Decisions Documentation:**   - Why Kafka? (High throughput, durability, partitioning)   - Why MongoDB + PostgreSQL? (Write vs Read optimization)   - Why KRaft? (Modern, simpler, no Zookeeper)   - Why Spark Streaming? (Flexibility, ML integration)   - Why dbt? (Testing, documentation, SQL-based)   - Why Airflow? (Mature, good UI, scheduling)   - Why FastAPI? (Async, auto-docs, fast)3. **Trade-offs Documented:**   - Spark Streaming vs Kafka Streams   - Real-time vs Batch (when to use each)   - dbt vs Spark for transformation   - Airflow vs Prefect vs Dagster   - MongoDB + PostgreSQL vs Single DB   - KRaft vs Zookeeper4. **Cost Estimation:**   - Hardware requirements   - Storage per month (MongoDB + PostgreSQL)   - Compute cost (Spark, Airflow)   - Network cost   - Optimization opportunities5. **20 Scenario Questions - Prepare Answers:**   - "What if Kafka goes down?"   - "How would you handle 10x data volume?"   - "Optimize this slow query"   - "Handle schema change"   - "What if MongoDB fails?"   - "What if PostgreSQL fails?"   - "How to scale to 1M sensors?"   - "What if data quality drops?"   - "How to reduce costs?"   - "What if need real-time ML predictions?"   - And 10 more scenarios...**INTERVIEW PREPARATION - Please also provide:**1. **Presentation Structure:**   - Opening (30 sec): Problem statement, solution overview   - Architecture (2 min): 10 layers, data flow   - Decisions (3 min): Why each technology, trade-offs   - Challenges (3 min): Problems faced, solutions   - Scalability (2 min): How to scale, optimizations   - Demo (3 min): Show working system   - Closing (30 sec): Key takeaways, learnings2. **Interview Questions - Comprehensive Answers:**      Q: "Walk me through your project"   â†’ Answer: "IoT pipeline: 100 sensors â†’ Kafka â†’ Spark Streaming (real-time) + Batch â†’ MongoDB (write) â†’ PostgreSQL (read) â†’ FastAPI â†’ Dashboards. End-to-end with monitoring."      Q: "Why these design choices?"   â†’ Answer: "Kafka for high throughput. MongoDB for writes, PostgreSQL for reads (optimization). Spark for flexibility. dbt for SQL transforms. Airflow for orchestration."      Q: "How would you scale it?"   â†’ Answer: "Horizontal scaling: More Kafka partitions, Spark cluster, DB replicas. Vertical: Increase resources. Optimize: Partitioning, caching, indexing."      Q: "What would you improve?"   â†’ Answer: "Add ML for anomaly detection, real-time dashboards, data lake for archival, better monitoring (Grafana), automated testing, disaster recovery."3. **Scenario Answers - Detailed:**   - For each of 20 scenarios, provide:     * Problem identification     * Solution approach     * Implementation steps     * Trade-offs     * Monitoring4. **Common Pitfalls to Avoid:**   - Don't over-engineer   - Don't claim to handle billion rows   - Don't say you'd use everything   - Be honest about limitations   - Show learning mindset5. **Portfolio Tips:**   - Clean GitHub repo   - Good README   - Architecture diagrams   - Demo video (optional)   - Blog post (optional)Please provide comprehensive interview prep material with all answers, scenarios, and presentation structure.
ðŸ“ HOW TO USE THESE PROMPTS
Copy the prompt for your current topic
Paste into Cursor AI chat
Cursor will:
Generate code implementation
Explain design decisions
Provide interview answers
Cover what-if scenarios
Give best practices
After each topic:
Review the code
Practice the interview answers
Test the what-if scenarios
Move to next topic
